# -*- coding: utf-8 -*-
"""
Kimi Vision APIèŠ‚ç‚¹
è°ƒç”¨Kimiè§†è§‰æ¨¡å‹APIè¿›è¡Œå›¾åƒç†è§£å’Œåˆ†æ
ä»…æ”¯æŒæœˆä¹‹æš—é¢å¹³å°
"""

import os
import base64
from io import BytesIO
from typing import Optional, List, Dict, Any
from pathlib import Path
import numpy as np
from PIL import Image

# å®šä¹‰æœåŠ¡å¹³å°é…ç½®
SERVICE_PLATFORMS = {
    "æœˆä¹‹æš—é¢": {
        "base_url": "https://api.moonshot.cn/v1",
        "api_key_env": "MOONSHOT_API_KEY",
        "config_key": "moonshot_api_key",
        "platform_key": "moonshot",
        "models": ["kimi-latest-8k", "kimi-latest-32k", "kimi-latest-128k"],
        "model_mapping": {
            "kimi-latest-8k": "kimi-latest",
            "kimi-latest-32k": "kimi-latest",
            "kimi-latest-128k": "kimi-latest"
        }
    }
}

# æ‰€æœ‰æ”¯æŒçš„Kimiè§†è§‰æ¨¡å‹
ALL_KIMI_VISION_MODELS = [
    "kimi-latest-8k", "kimi-latest-32k", "kimi-latest-128k"
]


class KimiVisionAPI:
    """
    Kimiè§†è§‰æ¨¡å‹APIè°ƒç”¨èŠ‚ç‚¹
    æ”¯æŒå›¾åƒç†è§£å’Œè§†è§‰é—®ç­”
    """
    
    # ç±»å±æ€§
    SERVICE_PLATFORMS = SERVICE_PLATFORMS
    ALL_KIMI_VISION_MODELS = ALL_KIMI_VISION_MODELS
    
    def __init__(self):
        """åˆå§‹åŒ–èŠ‚ç‚¹"""
        self.conversation_history = {}
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE", {
                    "tooltip": "è¾“å…¥è¦åˆ†æçš„å›¾åƒ"
                }),
                "text_input": ("STRING", {
                    "default": "è¯·è¯¦ç»†æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ã€‚",
                    "multiline": True,
                    "tooltip": "è¾“å…¥å…³äºå›¾åƒçš„é—®é¢˜æˆ–æŒ‡ä»¤"
                }),
                "platform": (["æœˆä¹‹æš—é¢"], {
                    "default": "æœˆä¹‹æš—é¢",
                    "tooltip": "Kimiè§†è§‰APIæœåŠ¡æä¾›å•†ï¼ˆä»…æ”¯æŒæœˆä¹‹æš—é¢ï¼‰"
                }),
                "model": (cls.ALL_KIMI_VISION_MODELS, {
                    "default": "kimi-latest-32k",
                    "tooltip": "é€‰æ‹©è¦ä½¿ç”¨çš„Kimiè§†è§‰æ¨¡å‹\nğŸ“‹ æ¨¡å‹è¯´æ˜ï¼š\nğŸ”¸ kimi-latest-8kï¼šé€‚åˆç®€å•å›¾åƒåˆ†æ\nğŸ”¸ kimi-latest-32kï¼šå¹³è¡¡æ€§èƒ½å’Œè´¨é‡\nğŸ”¸ kimi-latest-128kï¼šæœ€ä½³è´¨é‡ï¼Œé€‚åˆå¤æ‚åˆ†æ"
                }),
                "max_tokens": ("INT", {
                    "default": 2048,
                    "min": 1,
                    "max": 16384,
                    "step": 1,
                    "tooltip": "æ¨¡å‹ç”Ÿæˆæ–‡æœ¬æ—¶æœ€å¤šèƒ½ä½¿ç”¨çš„tokenæ•°é‡"
                }),
                "history": ("INT", {
                    "default": 3,
                    "min": 1,
                    "max": 10,
                    "step": 1,
                    "tooltip": "ä¿æŒçš„å†å²å¯¹è¯è½®æ•°ï¼ˆè§†è§‰æ¨¡å‹å»ºè®®è¾ƒå°‘è½®æ•°ï¼‰"
                }),
            },
            "optional": {
                "temperature": ("FLOAT", {
                    "default": 0.5,
                    "min": 0.0,
                    "max": 2.0,
                    "step": 0.1,
                    "tooltip": "æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§ï¼Œè§†è§‰ä»»åŠ¡å»ºè®®è¾ƒä½å€¼"
                }),
                "top_p": ("FLOAT", {
                    "default": 0.8,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.1,
                    "tooltip": "æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„å¤šæ ·æ€§"
                }),
                "image_quality": (["auto", "low", "high"], {
                    "default": "auto",
                    "tooltip": "å›¾åƒè´¨é‡è®¾ç½®ï¼šautoè‡ªåŠ¨ï¼Œlowä½è´¨é‡å¿«é€Ÿï¼Œhighé«˜è´¨é‡ç²¾ç¡®"
                }),
                "clear_history": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦æ¸…é™¤å†å²å¯¹è¯è®°å½•"
                }),
            }
        }

    RETURN_TYPES = ("STRING", "STRING", "INT")
    RETURN_NAMES = ("analysis_result", "conversation_info", "total_tokens")
    FUNCTION = "analyze_image"
    CATEGORY = "ğŸ¨QING/APIè°ƒç”¨"
    OUTPUT_NODE = False

    def _get_api_key(self, platform_config: Dict[str, str]) -> str:
        """è·å–APIå¯†é’¥ï¼ˆæ”¯æŒå¤šå¹³å°ï¼‰"""
        final_api_key = ""
        config_key = platform_config["config_key"]

        # ç­–ç•¥1: ä»ç¯å¢ƒå˜é‡è·å–
        final_api_key = os.getenv(platform_config["api_key_env"], '')

        # ç­–ç•¥2: ä»ğŸ¨QINGé…ç½®ç³»ç»Ÿè·å–
        if not final_api_key:
            try:
                from .config_server import get_api_key_by_platform
                final_api_key = get_api_key_by_platform(config_key)
            except ImportError:
                try:
                    # å°è¯•ä»æ–°çš„é…ç½®ç®¡ç†å™¨è·å–
                    from .settings_approach import get_qing_api_key_improved
                    final_api_key = get_qing_api_key_improved(config_key)
                except ImportError:
                    pass

        # ç­–ç•¥3: ä»ä¸´æ—¶æ–‡ä»¶è·å–ï¼ˆå…¼å®¹æ€§ï¼‰
        if not final_api_key:
            try:
                import tempfile
                temp_file = Path(tempfile.gettempdir()) / f"qing_{config_key}_temp.txt"
                if temp_file.exists():
                    with open(temp_file, 'r', encoding='utf-8') as f:
                        temp_key = f.read().strip()
                        if temp_key:
                            final_api_key = temp_key
            except Exception:
                pass

        return final_api_key

    def _image_to_base64(self, image, quality: str = "auto") -> str:
        """å°†ComfyUIå›¾åƒè½¬æ¢ä¸ºbase64æ ¼å¼"""
        try:
            # å°†PyTorch tensorè½¬æ¢ä¸ºnumpy array
            if hasattr(image, 'cpu'):
                image = image.cpu().numpy()
            elif hasattr(image, 'numpy'):
                image = image.numpy()
            elif not isinstance(image, np.ndarray):
                image = np.array(image)
            
            # ComfyUIå›¾åƒæ ¼å¼è½¬æ¢ (batch, height, width, channels) -> PIL Image
            if len(image.shape) == 4:
                image = image[0]  # å–ç¬¬ä¸€å¼ å›¾ç‰‡
            
            # ç¡®ä¿å€¼åœ¨0-255èŒƒå›´å†…
            if image.max() <= 1.0:
                image = (image * 255).astype(np.uint8)
            else:
                image = image.astype(np.uint8)
            
            # è½¬æ¢ä¸ºPIL Image
            pil_image = Image.fromarray(image)
            
            # æ ¹æ®è´¨é‡è®¾ç½®è°ƒæ•´å›¾åƒ
            if quality == "low":
                # ä½è´¨é‡ï¼šç¼©å°å›¾åƒï¼Œä½¿ç”¨JPEGå‹ç¼©
                pil_image.thumbnail((512, 512), Image.Resampling.LANCZOS)
                format_type = "JPEG"
                encode_params = {"quality": 60, "optimize": True}
            elif quality == "high":
                # é«˜è´¨é‡ï¼šä¿æŒåŸå°ºå¯¸ï¼Œä½¿ç”¨PNG
                max_size = 2048
                if max(pil_image.size) > max_size:
                    pil_image.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
                format_type = "PNG"
                encode_params = {}
            else:  # auto
                # è‡ªåŠ¨ï¼šæ ¹æ®å›¾åƒå¤§å°æ™ºèƒ½é€‰æ‹©
                if max(pil_image.size) > 1024:
                    pil_image.thumbnail((1024, 1024), Image.Resampling.LANCZOS)
                format_type = "JPEG"
                encode_params = {"quality": 85, "optimize": True}
            
            # ç¼–ç ä¸ºbase64
            buffer = BytesIO()
            pil_image.save(buffer, format=format_type, **encode_params)
            image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            
            return f"data:image/{format_type.lower()};base64,{image_base64}"
            
        except Exception as e:
            raise Exception(f"å›¾åƒè½¬æ¢å¤±è´¥: {str(e)}")

    def analyze_image(self, image, text_input: str, platform: str, model: str, 
                     max_tokens: int, history: int,
                     temperature: Optional[float] = 0.5, top_p: Optional[float] = 0.8,
                     image_quality: Optional[str] = "auto", clear_history: Optional[bool] = False):
        """
        è°ƒç”¨Kimi Vision APIåˆ†æå›¾åƒ

        Args:
            image: è¾“å…¥å›¾åƒ
            text_input: è¾“å…¥æ–‡æœ¬
            platform: æœåŠ¡å¹³å°
            model: æ¨¡å‹åç§°
            max_tokens: æœ€å¤§tokenæ•°
            history: ä¿æŒçš„å†å²è½®æ•°
            temperature: æ¸©åº¦å‚æ•°
            top_p: top_på‚æ•°
            image_quality: å›¾åƒè´¨é‡
            clear_history: æ˜¯å¦æ¸…é™¤å†å²

        Returns:
            tuple: (åˆ†æç»“æœ, å¯¹è¯ä¿¡æ¯, tokenæ•°é‡)
        """
        try:
            # æ¸…é™¤å†å²è®°å½•
            if clear_history:
                self.conversation_history.clear()

            # è·å–å¹³å°é…ç½®
            platform_config = self.SERVICE_PLATFORMS.get(platform)
            if not platform_config:
                return (f"é”™è¯¯ï¼šä¸æ”¯æŒçš„å¹³å° '{platform}'", "é”™è¯¯çŠ¶æ€", 0)

            # éªŒè¯æ¨¡å‹æ˜¯å¦è¢«å½“å‰å¹³å°æ”¯æŒ
            supported_models = platform_config.get("models", [])
            if model not in supported_models:
                available_models = ", ".join(supported_models)
                return (f"âŒ æ¨¡å‹å…¼å®¹æ€§é”™è¯¯\n\nğŸŒ™ å¹³å° '{platform}' ä¸æ”¯æŒæ¨¡å‹ '{model}'\n\nâœ… è¯¥å¹³å°æ”¯æŒçš„æ¨¡å‹ï¼š\n{available_models}", "æ¨¡å‹ä¸å…¼å®¹", 0)

            # è·å–APIå¯†é’¥
            api_key = self._get_api_key(platform_config)
            if not api_key:
                error_msg = f"""é”™è¯¯ï¼šæœªæä¾›{platform}çš„APIå¯†é’¥ã€‚è¯·å°è¯•ä»¥ä¸‹æ–¹æ³•ä¹‹ä¸€ï¼š

1. è®¾ç½®ç¯å¢ƒå˜é‡ï¼š{platform_config['api_key_env']}
2. åœ¨ğŸ¨QINGè®¾ç½®ä¸­é…ç½®APIå¯†é’¥
3. ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶è®¾ç½®å¯†é’¥

è¯·é…ç½®åé‡è¯•ã€‚"""
                return (error_msg, "APIå¯†é’¥ç¼ºå¤±", 0)

            # å¯¼å…¥openaiåº“
            try:
                from openai import OpenAI
            except ImportError:
                return ("é”™è¯¯ï¼šæœªå®‰è£…openaiåº“ã€‚è¯·è¿è¡Œï¼špip install openai", "ä¾èµ–ç¼ºå¤±", 0)

            # åˆå§‹åŒ–å®¢æˆ·ç«¯
            client = OpenAI(
                base_url=platform_config["base_url"],
                api_key=api_key
            )

            # è·å–å¯¹è¯å†å² - ä½¿ç”¨è‹±æ–‡å¹³å°é”®é¿å…ç¼–ç é—®é¢˜
            platform_key = platform_config.get("platform_key", platform)
            conversation_key = f"{platform_key}_{model}_vision"
            if conversation_key not in self.conversation_history:
                self.conversation_history[conversation_key] = []

            current_history = self.conversation_history[conversation_key]

            # è½¬æ¢å›¾åƒä¸ºbase64
            image_base64 = self._image_to_base64(image, image_quality)

            # æ„å»ºæ¶ˆæ¯å†…å®¹
            message_content = [
                {
                    "type": "text",
                    "text": text_input
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": image_base64,
                        "detail": image_quality if image_quality != "auto" else "auto"
                    }
                }
            ]

            # æ·»åŠ å½“å‰è¾“å…¥åˆ°å†å²
            current_history.append({"role": "user", "content": message_content})

            # é™åˆ¶å†å²é•¿åº¦ï¼ˆè§†è§‰æ¨¡å‹å»ºè®®æ›´å°‘çš„å†å²ï¼‰
            if len(current_history) > history * 2:
                current_history = current_history[-(history * 2):]
                self.conversation_history[conversation_key] = current_history

            # æ ¹æ®å¹³å°è·å–å¯¹åº”çš„æ¨¡å‹åç§°
            platform_model_mapping = platform_config.get("model_mapping", {})
            api_model_name = platform_model_mapping.get(model, model.lower())

            # è°ƒç”¨API
            response = client.chat.completions.create(
                model=api_model_name,
                messages=current_history,
                max_tokens=max_tokens,
                temperature=temperature,
                top_p=top_p
            )

            # æå–å›å¤
            reply = response.choices[0].message.content

            # æ·»åŠ å›å¤åˆ°å†å²
            current_history.append({"role": "assistant", "content": reply})

            # è®¡ç®—tokenä½¿ç”¨æƒ…å†µ
            if hasattr(response, 'usage') and response.usage:
                total_tokens = response.usage.total_tokens
                prompt_tokens = getattr(response.usage, 'prompt_tokens', 0)
                completion_tokens = getattr(response.usage, 'completion_tokens', 0)
                token_count = total_tokens
            else:
                total_tokens = completion_tokens = prompt_tokens = token_count = 0

            # ç”Ÿæˆå¯¹è¯ä¿¡æ¯
            conversation_info = f"å¹³å°: {platform} | æ¨¡å‹: {model} | å›¾åƒè´¨é‡: {image_quality} | å†å²è½®æ•°: {len(current_history)//2} | æ€»Tokens: {total_tokens} (è¾“å…¥: {prompt_tokens}, è¾“å‡º: {completion_tokens}, é™åˆ¶: {max_tokens})"

            return (reply, conversation_info, token_count)

        except Exception as e:
            error_message = f"Kimi Vision APIè°ƒç”¨å¤±è´¥ ({platform}): {str(e)}"
            return (error_message, "é”™è¯¯çŠ¶æ€", 0)

    @classmethod
    def IS_CHANGED(cls, **kwargs):
        # æ¯æ¬¡éƒ½é‡æ–°æ‰§è¡Œï¼Œå› ä¸ºæ˜¯APIè°ƒç”¨
        return float("nan")


# ComfyUIèŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "KimiVisionAPI": KimiVisionAPI
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "KimiVisionAPI": "Kimi_è§†è§‰ä¸¨API"
}
