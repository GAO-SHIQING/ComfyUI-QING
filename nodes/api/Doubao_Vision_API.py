# -*- coding: utf-8 -*-
"""
Doubao Vision APIèŠ‚ç‚¹
è°ƒç”¨Doubaoè§†è§‰æ¨¡å‹APIè¿›è¡Œå›¾åƒç†è§£å’Œåˆ†æ
ä»…æ”¯æŒç«å±±å¼•æ“å¹³å°
"""

import os
import base64
from io import BytesIO
from typing import Optional, List, Dict, Any
from pathlib import Path
import numpy as np
from PIL import Image

# å®šä¹‰æœåŠ¡å¹³å°é…ç½®
SERVICE_PLATFORMS = {
    "ç«å±±å¼•æ“": {
        "base_url": "https://ark.cn-beijing.volces.com/api/v3",
        "api_key_env": "VOLC_API_KEY",
        "config_key": "volcengine_api_key",
        "platform_key": "volcengine",
        "models": [
            "Doubao-Seed-1.6", 
            "Doubao-Seed-1.6-thinking", 
            "Doubao-Seed-1.6-flash", 
            "Doubao-Seed-1.6-vision", 
            "Doubao-1.5-vision-pro", 
            "Doubao-1.5-vision-lite", 
            "Doubao-1.5-thinking-vision-pro",
            "Doubao-1.5-UI-TARS",
            "Doubao-Seed-Translation"
        ],
        "model_mapping": {
            "Doubao-Seed-1.6": "doubao-seed-1-6-250615",
            "Doubao-Seed-1.6-thinking": "doubao-seed-1-6-thinking-250715",
            "Doubao-Seed-1.6-flash": "doubao-seed-1-6-flash-250828",
            "Doubao-Seed-1.6-vision": "doubao-seed-1-6-vision-250815",
            "Doubao-1.5-vision-pro": "doubao-1.5-vision-pro-250328",
            "Doubao-1.5-vision-lite": "doubao-1.5-vision-lite-250315",
            "Doubao-1.5-thinking-vision-pro": "doubao-1-5-thinking-vision-pro-250428",
            "Doubao-1.5-UI-TARS": "doubao-1-5-ui-tars-250428",
            "Doubao-Seed-Translation": "doubao-seed-translation-250915"
        }
    }
}

# æ‰€æœ‰æ”¯æŒçš„Doubaoè§†è§‰æ¨¡å‹
ALL_DOUBAO_VISION_MODELS = [
    "Doubao-Seed-1.6", 
    "Doubao-Seed-1.6-thinking", 
    "Doubao-Seed-1.6-flash", 
    "Doubao-Seed-1.6-vision", 
    "Doubao-1.5-vision-pro", 
    "Doubao-1.5-vision-lite", 
    "Doubao-1.5-thinking-vision-pro",
    "Doubao-1.5-UI-TARS",
    "Doubao-Seed-Translation"
]


class DoubaoVisionAPI:
    """
    Doubaoè§†è§‰æ¨¡å‹APIè°ƒç”¨èŠ‚ç‚¹
    æ”¯æŒå›¾åƒç†è§£å’Œè§†è§‰é—®ç­”
    """
    
    # ç±»å±æ€§
    SERVICE_PLATFORMS = SERVICE_PLATFORMS
    ALL_DOUBAO_VISION_MODELS = ALL_DOUBAO_VISION_MODELS
    
    def __init__(self):
        """åˆå§‹åŒ–èŠ‚ç‚¹"""
        self.conversation_history = {}
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE", {
                    "tooltip": "è¾“å…¥è¦åˆ†æçš„å›¾åƒ"
                }),
                "text_input": ("STRING", {
                    "default": "è¯·è¯¦ç»†åˆ†æè¿™å¼ å›¾ç‰‡çš„å†…å®¹å’Œç»†èŠ‚ã€‚",
                    "multiline": True,
                    "tooltip": "è¾“å…¥å…³äºå›¾åƒçš„é—®é¢˜æˆ–æŒ‡ä»¤"
                }),
                "platform": (["ç«å±±å¼•æ“"], {
                    "default": "ç«å±±å¼•æ“",
                    "tooltip": "Doubaoè§†è§‰APIæœåŠ¡æä¾›å•†ï¼ˆä»…æ”¯æŒç«å±±å¼•æ“ï¼‰"
                }),
                "model": (cls.ALL_DOUBAO_VISION_MODELS, {
                    "default": "Doubao-1.5-vision-pro",
                    "tooltip": "é€‰æ‹©è¦ä½¿ç”¨çš„Doubaoè§†è§‰æ¨¡å‹\nğŸ“‹ æ¨¡å‹è¯´æ˜ï¼š\nğŸ”¸ Doubao-Seed-1.6ï¼šæœ€æ–°ç§å­æ¨¡å‹\nğŸ”¸ Doubao-Seed-1.6-thinkingï¼šæ€ç»´é“¾æ¨ç†\nğŸ”¸ Doubao-Seed-1.6-flashï¼šå¿«é€Ÿå“åº”\nğŸ”¸ Doubao-Seed-1.6-visionï¼šä¸“ä¸šè§†è§‰\nğŸ”¸ Doubao-1.5-vision-proï¼šé«˜è´¨é‡è§†è§‰åˆ†æ\nğŸ”¸ Doubao-1.5-vision-liteï¼šè½»é‡çº§è§†è§‰\nğŸ”¸ Doubao-1.5-thinking-vision-proï¼šæ€ç»´é“¾è§†è§‰ä¸“ä¸šç‰ˆ\nğŸ”¸ Doubao-1.5-UI-TARSï¼šUIç•Œé¢åˆ†æä¸“ç”¨\nğŸ”¸ Doubao-Seed-Translationï¼šç¿»è¯‘ä¸“ç”¨æ¨¡å‹"
                }),
                "max_tokens": ("INT", {
                    "default": 2048,
                    "min": 1,
                    "max": 8192,
                    "step": 1,
                    "tooltip": "æ¨¡å‹ç”Ÿæˆæ–‡æœ¬æ—¶æœ€å¤šèƒ½ä½¿ç”¨çš„tokenæ•°é‡"
                }),
                "history": ("INT", {
                    "default": 3,
                    "min": 1,
                    "max": 10,
                    "step": 1,
                    "tooltip": "ä¿æŒçš„å†å²å¯¹è¯è½®æ•°ï¼ˆè§†è§‰æ¨¡å‹å»ºè®®è¾ƒå°‘è½®æ•°ï¼‰"
                }),
            },
            "optional": {
                "temperature": ("FLOAT", {
                    "default": 0.3,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.1,
                    "tooltip": "æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§ï¼Œè§†è§‰ä»»åŠ¡å»ºè®®è¾ƒä½å€¼"
                }),
                "top_p": ("FLOAT", {
                    "default": 0.8,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.1,
                    "tooltip": "æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„å¤šæ ·æ€§"
                }),
                "image_quality": (["auto", "low", "high"], {
                    "default": "auto",
                    "tooltip": "å›¾åƒè´¨é‡è®¾ç½®ï¼šautoè‡ªåŠ¨ï¼Œlowä½è´¨é‡å¿«é€Ÿï¼Œhighé«˜è´¨é‡ç²¾ç¡®"
                }),
                "clear_history": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦æ¸…é™¤å†å²å¯¹è¯è®°å½•"
                }),
            }
        }

    RETURN_TYPES = ("STRING", "STRING", "INT")
    RETURN_NAMES = ("analysis_result", "conversation_info", "total_tokens")
    FUNCTION = "analyze_image"
    CATEGORY = "ğŸ¨QING/APIè°ƒç”¨"
    OUTPUT_NODE = False

    def _get_api_key(self, platform_config: Dict[str, str]) -> str:
        """è·å–APIå¯†é’¥ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ - å‡å°‘å»¶è¿Ÿï¼‰"""
        config_key = platform_config["config_key"]
        
        # ç¼“å­˜å¯¼å…¥çš„æ¨¡å—ä»¥é¿å…é‡å¤å¯¼å…¥
        if not hasattr(self, '_config_modules_loaded'):
            self._config_server = None
            self._settings_approach = None
            try:
                from .config_server import get_api_key_by_platform
                self._config_server = get_api_key_by_platform
            except ImportError:
                try:
                    from .settings_approach import get_qing_api_key_improved
                    self._settings_approach = get_qing_api_key_improved
                except ImportError:
                    pass
            self._config_modules_loaded = True

        # ç­–ç•¥1: ä»ç¯å¢ƒå˜é‡è·å–ï¼ˆæœ€å¿«ï¼‰
        api_key = os.getenv(platform_config["api_key_env"], '')
        if api_key:
            return api_key

        # ç­–ç•¥2: ä»ğŸ¨QINGé…ç½®ç³»ç»Ÿè·å–
        if self._config_server:
            try:
                api_key = self._config_server(config_key)
                if api_key:
                    return api_key
            except Exception:
                pass
        
        if self._settings_approach:
            try:
                api_key = self._settings_approach(config_key)
                if api_key:
                    return api_key
            except Exception:
                pass

        # ç­–ç•¥3: ä»ä¸´æ—¶æ–‡ä»¶è·å–ï¼ˆæœ€æ…¢ï¼Œæœ€åå°è¯•ï¼‰
        try:
            import tempfile
            temp_file = Path(tempfile.gettempdir()) / f"qing_{config_key}_temp.txt"
            if temp_file.exists():
                with open(temp_file, 'r', encoding='utf-8') as f:
                    temp_key = f.read().strip()
                    if temp_key:
                        return temp_key
        except Exception:
            pass

        return ""

    def _image_to_base64(self, image, quality: str = "auto") -> str:
        """å°†ComfyUIå›¾åƒè½¬æ¢ä¸ºbase64æ ¼å¼"""
        try:
            # å°†PyTorch tensorè½¬æ¢ä¸ºnumpy array
            if hasattr(image, 'cpu'):
                image = image.cpu().numpy()
            elif hasattr(image, 'numpy'):
                image = image.numpy()
            elif not isinstance(image, np.ndarray):
                image = np.array(image)
            
            # ComfyUIå›¾åƒæ ¼å¼è½¬æ¢ (batch, height, width, channels) -> PIL Image
            if len(image.shape) == 4:
                image = image[0]  # å–ç¬¬ä¸€å¼ å›¾ç‰‡
            
            # ç¡®ä¿å€¼åœ¨0-255èŒƒå›´å†…
            if image.max() <= 1.0:
                image = (image * 255).astype(np.uint8)
            else:
                image = image.astype(np.uint8)
            
            # è½¬æ¢ä¸ºPIL Image
            pil_image = Image.fromarray(image)
            
            # æ ¹æ®è´¨é‡è®¾ç½®è°ƒæ•´å›¾åƒï¼ˆä¼˜åŒ–é‡é‡‡æ ·ç®—æ³•ï¼‰
            if quality == "low":
                # ä½è´¨é‡ï¼šç¼©å°å›¾åƒï¼Œä½¿ç”¨å¿«é€Ÿé‡é‡‡æ ·
                pil_image.thumbnail((512, 512), Image.Resampling.BILINEAR)
                format_type = "JPEG"
                encode_params = {"quality": 70, "optimize": True}
            elif quality == "high":
                # é«˜è´¨é‡ï¼šä¿æŒåŸå°ºå¯¸ï¼Œä½¿ç”¨é«˜è´¨é‡é‡é‡‡æ ·
                max_size = 2048
                if max(pil_image.size) > max_size:
                    pil_image.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)
                format_type = "JPEG"  # æ”¹ä¸ºJPEGä»¥å‡å°‘æ–‡ä»¶å¤§å°
                encode_params = {"quality": 95, "optimize": True}
            else:  # auto
                # è‡ªåŠ¨ï¼šå¹³è¡¡è´¨é‡å’Œé€Ÿåº¦
                if max(pil_image.size) > 1024:
                    pil_image.thumbnail((1024, 1024), Image.Resampling.BILINEAR)
                format_type = "JPEG"
                encode_params = {"quality": 85, "optimize": True}
            
            # ç¼–ç ä¸ºbase64
            buffer = BytesIO()
            pil_image.save(buffer, format=format_type, **encode_params)
            image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            
            return f"data:image/{format_type.lower()};base64,{image_base64}"
            
        except Exception as e:
            raise Exception(f"å›¾åƒè½¬æ¢å¤±è´¥: {str(e)}")

    def analyze_image(self, image, text_input: str, platform: str, model: str, 
                     max_tokens: int, history: int,
                     temperature: Optional[float] = 0.3, top_p: Optional[float] = 0.8,
                     image_quality: Optional[str] = "auto", clear_history: Optional[bool] = False):
        """
        è°ƒç”¨Doubao Vision APIåˆ†æå›¾åƒ

        Args:
            image: è¾“å…¥å›¾åƒ
            text_input: è¾“å…¥æ–‡æœ¬
            platform: æœåŠ¡å¹³å°
            model: æ¨¡å‹åç§°
            max_tokens: æœ€å¤§tokenæ•°
            history: ä¿æŒçš„å†å²è½®æ•°
            temperature: æ¸©åº¦å‚æ•°
            top_p: top_på‚æ•°
            image_quality: å›¾åƒè´¨é‡
            clear_history: æ˜¯å¦æ¸…é™¤å†å²

        Returns:
            tuple: (åˆ†æç»“æœ, å¯¹è¯ä¿¡æ¯, tokenæ•°é‡)
        """
        try:
            # æ¸…é™¤å†å²è®°å½•
            if clear_history:
                self.conversation_history.clear()

            # è·å–å¹³å°é…ç½®
            platform_config = self.SERVICE_PLATFORMS.get(platform)
            if not platform_config:
                return (f"é”™è¯¯ï¼šä¸æ”¯æŒçš„å¹³å° '{platform}'", "é”™è¯¯çŠ¶æ€", 0)

            # éªŒè¯æ¨¡å‹æ˜¯å¦è¢«å½“å‰å¹³å°æ”¯æŒ
            supported_models = platform_config.get("models", [])
            if model not in supported_models:
                available_models = ", ".join(supported_models)
                return (f"âŒ æ¨¡å‹å…¼å®¹æ€§é”™è¯¯\n\nğŸŒ‹ å¹³å° '{platform}' ä¸æ”¯æŒæ¨¡å‹ '{model}'\n\nâœ… è¯¥å¹³å°æ”¯æŒçš„æ¨¡å‹ï¼š\n{available_models}", "æ¨¡å‹ä¸å…¼å®¹", 0)

            # è·å–APIå¯†é’¥
            api_key = self._get_api_key(platform_config)
            if not api_key:
                error_msg = f"""é”™è¯¯ï¼šæœªæä¾›{platform}çš„APIå¯†é’¥ã€‚è¯·å°è¯•ä»¥ä¸‹æ–¹æ³•ä¹‹ä¸€ï¼š

1. è®¾ç½®ç¯å¢ƒå˜é‡ï¼š{platform_config['api_key_env']}
2. åœ¨ğŸ¨QINGè®¾ç½®ä¸­é…ç½®APIå¯†é’¥
3. ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶è®¾ç½®å¯†é’¥

è¯·é…ç½®åé‡è¯•ã€‚"""
                return (error_msg, "APIå¯†é’¥ç¼ºå¤±", 0)

            # å¯¼å…¥openaiåº“
            try:
                from openai import OpenAI
            except ImportError:
                return ("é”™è¯¯ï¼šæœªå®‰è£…openaiåº“ã€‚è¯·è¿è¡Œï¼špip install openai", "ä¾èµ–ç¼ºå¤±", 0)

            # åˆå§‹åŒ–å®¢æˆ·ç«¯
            client = OpenAI(
                base_url=platform_config["base_url"],
                api_key=api_key
            )

            # è·å–å¯¹è¯å†å² - ä½¿ç”¨è‹±æ–‡å¹³å°é”®é¿å…ç¼–ç é—®é¢˜
            platform_key = platform_config.get("platform_key", platform)
            conversation_key = f"{platform_key}_{model}_vision"
            if conversation_key not in self.conversation_history:
                self.conversation_history[conversation_key] = []

            current_history = self.conversation_history[conversation_key]

            # è½¬æ¢å›¾åƒä¸ºbase64
            image_base64 = self._image_to_base64(image, image_quality)

            # æ„å»ºæ¶ˆæ¯å†…å®¹
            message_content = [
                {
                    "type": "text",
                    "text": text_input
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": image_base64,
                        "detail": image_quality if image_quality != "auto" else "auto"
                    }
                }
            ]

            # æ·»åŠ å½“å‰è¾“å…¥åˆ°å†å²
            current_history.append({"role": "user", "content": message_content})

            # é™åˆ¶å†å²é•¿åº¦ï¼ˆè§†è§‰æ¨¡å‹å»ºè®®æ›´å°‘çš„å†å²ï¼‰
            if len(current_history) > history * 2:
                current_history = current_history[-(history * 2):]
                self.conversation_history[conversation_key] = current_history

            # æ ¹æ®å¹³å°è·å–å¯¹åº”çš„æ¨¡å‹åç§°
            platform_model_mapping = platform_config.get("model_mapping", {})
            api_model_name = platform_model_mapping.get(model, model.lower())

            # è°ƒç”¨API
            response = client.chat.completions.create(
                model=api_model_name,
                messages=current_history,
                max_tokens=max_tokens,
                temperature=temperature,
                top_p=top_p
            )

            # æå–å›å¤
            reply = response.choices[0].message.content

            # æ·»åŠ å›å¤åˆ°å†å²
            current_history.append({"role": "assistant", "content": reply})

            # è®¡ç®—tokenä½¿ç”¨æƒ…å†µ
            if hasattr(response, 'usage') and response.usage:
                total_tokens = response.usage.total_tokens
                prompt_tokens = getattr(response.usage, 'prompt_tokens', 0)
                completion_tokens = getattr(response.usage, 'completion_tokens', 0)
                token_count = total_tokens
            else:
                total_tokens = completion_tokens = prompt_tokens = token_count = 0

            # ç”Ÿæˆå¯¹è¯ä¿¡æ¯
            conversation_info = f"å¹³å°: {platform} | æ¨¡å‹: {model} | å›¾åƒè´¨é‡: {image_quality} | å†å²è½®æ•°: {len(current_history)//2} | æ€»Tokens: {total_tokens} (è¾“å…¥: {prompt_tokens}, è¾“å‡º: {completion_tokens}, é™åˆ¶: {max_tokens})"

            return (reply, conversation_info, token_count)

        except Exception as e:
            error_message = f"Doubao Vision APIè°ƒç”¨å¤±è´¥ ({platform}): {str(e)}"
            return (error_message, "é”™è¯¯çŠ¶æ€", 0)

    @classmethod
    def IS_CHANGED(cls, **kwargs):
        # æ¯æ¬¡éƒ½é‡æ–°æ‰§è¡Œï¼Œå› ä¸ºæ˜¯APIè°ƒç”¨
        return float("nan")


# ComfyUIèŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "DoubaoVisionAPI": DoubaoVisionAPI
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "DoubaoVisionAPI": "Doubao_è§†è§‰ä¸¨API"
}
