# -*- coding: utf-8 -*-
"""
Gemini Vision APIèŠ‚ç‚¹ - åŸºäºé€šç”¨æ¡†æ¶
è°ƒç”¨Geminiè§†è§‰æ¨¡å‹APIè¿›è¡Œå›¾åƒç†è§£å’Œåˆ†æ
æ”¯æŒGoogle AI Studioå¹³å°
"""

from typing import Dict, Any
from .base_api_framework import (
    BaseVisionAPINode, 
    BasePlatformAdapter, 
    PlatformConfig
)


class GoogleAIStudioGeminiVisionAdapter(BasePlatformAdapter):
    """Google AI Studio Geminiè§†è§‰å¹³å°é€‚é…å™¨"""
    
    def prepare_api_params(self, base_params: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        params = base_params.copy()
        
        # Geminiä¸æ”¯æŒé‡å¤æƒ©ç½šå‚æ•°ï¼Œä½†ä¿æŒå…¼å®¹æ€§
        repetition_penalty = kwargs.get('repetition_penalty', 1.0)
        if repetition_penalty != 1.0:
            # Geminiä½¿ç”¨ä¸åŒçš„å‚æ•°åï¼Œè½¬æ¢ä¸ºtemperatureè°ƒæ•´
            current_temp = params.get('temperature', 0.4)
            adjusted_temp = max(0.0, min(2.0, current_temp + (repetition_penalty - 1.0) * 0.3))
            params['temperature'] = adjusted_temp
        
        # åº”ç”¨tokené™åˆ¶
        params["max_tokens"] = self.apply_token_limit(params["max_tokens"])
        
        # Google AI Studioç‰¹å®šå‚æ•°
        # æ·»åŠ å›¾åƒè´¨é‡å‚æ•°æ”¯æŒ
        image_quality = kwargs.get('image_quality', 'auto')
        params = self.handle_image_quality(params, image_quality)
        
        # æ ¹æ®æ–‡æ¡£ï¼ŒGemini APIé€šè¿‡OpenAIå…¼å®¹å±‚æ”¯æŒæ€è€ƒåŠŸèƒ½
        # å¯ä»¥æ·»åŠ reasoning_effortå‚æ•°ï¼ˆlow, medium, highï¼‰
        reasoning_effort = kwargs.get('reasoning_effort', None)
        if reasoning_effort and reasoning_effort in ['low', 'medium', 'high']:
            params["reasoning_effort"] = reasoning_effort
        
        return params


class GeminiVisionAPI(BaseVisionAPINode):
    """
    Geminiè§†è§‰æ¨¡å‹APIè°ƒç”¨èŠ‚ç‚¹ - æ¡†æ¶ç‰ˆæœ¬
    æ”¯æŒGoogle AI Studioå¹³å°çš„Geminiè§†è§‰æ¨¡å‹è°ƒç”¨
    """
    
    # èŠ‚ç‚¹ä¿¡æ¯
    NODE_NAME = "GeminiVisionAPI"
    DISPLAY_NAME = "Gemini_è§†è§‰ä¸¨API"
    
    # é‡å†™è¿”å›åç§°ä»¥é€‚åˆè§†è§‰åˆ†æ
    RETURN_NAMES = ("analysis_result", "conversation_info", "total_tokens")
    
    # å¹³å°é…ç½®
    PLATFORM_CONFIGS = {
        "Google AI Studio": PlatformConfig(
            name="Google AI Studio",
            base_url="https://generativelanguage.googleapis.com/v1beta/openai/",
            api_key_env="GEMINI_API_KEY",
            config_key="gemini_api_key",
            platform_key="google_ai_studio_vision",
            models=[
                "gemini-2.5-pro",
                "gemini-2.5-flash-preview-09-2025",
                "gemini-2.5-flash-lite-preview-09-2025",
                "gemini-2.5-flash", 
                "gemini-2.5-flash-lite",
                "gemini-2.0-flash"
            ],
            model_mapping={
                "gemini-2.5-pro": "gemini-2.5-pro",
                "gemini-2.5-flash": "gemini-2.5-flash",
                "gemini-2.5-flash-lite": "gemini-2.5-flash-lite", 
                "gemini-2.0-flash": "gemini-2.0-flash",
                "gemini-2.5-flash-preview-09-2025": "gemini-2.5-flash-preview-09-2025",
                "gemini-2.5-flash-lite-preview-09-2025": "gemini-2.5-flash-lite-preview-09-2025"
            },
            max_tokens_limit=8192,
            supports_frequency_penalty=False,  # Geminiä½¿ç”¨ä¸åŒçš„å‚æ•°æ§åˆ¶
            supports_repetition_penalty=False
        )
    }
    
    # å¹³å°é€‚é…å™¨æ˜ å°„
    PLATFORM_ADAPTERS = {
        "Google AI Studio": GoogleAIStudioGeminiVisionAdapter
    }
    
    @classmethod
    def get_input_types(cls) -> Dict[str, Any]:
        """é‡å†™è¾“å…¥ç±»å‹ä»¥æ·»åŠ Geminiè§†è§‰ç‰¹å®šçš„æç¤ºä¿¡æ¯å’Œå›¾åƒè´¨é‡å‚æ•°"""
        base_types = super().get_input_types()
        
        # è‡ªå®šä¹‰Geminiè§†è§‰çš„æç¤ºä¿¡æ¯
        base_types["required"]["text_input"][1]["tooltip"] = "è¾“å…¥è¦å‘é€ç»™Geminiè§†è§‰æ¨¡å‹çš„æ–‡æœ¬é—®é¢˜ï¼ŒGeminiæ“…é•¿å›¾åƒç†è§£ã€å¤šæ¨¡æ€æ¨ç†ã€ä»£ç ç”Ÿæˆå’Œå¤æ‚è§†è§‰åˆ†æ"
        base_types["required"]["model"][1]["tooltip"] = """é€‰æ‹©è¦ä½¿ç”¨çš„Geminiè§†è§‰æ¨¡å‹
ğŸ“‹ Google AI Studioæ¨¡å‹ç‰¹ç‚¹ï¼š
ğŸ”¸ gemini-2.5-proï¼šæœ€æ–°ä¸“ä¸šç‰ˆï¼Œæœ€å¼ºæ€§èƒ½å’Œæ€è€ƒèƒ½åŠ›
ğŸ”¸ gemini-2.5-flash-preview-09-2025ï¼š2025å¹´9æœˆé¢„è§ˆç‰ˆFlashæ¨¡å‹ï¼Œæœ€æ–°ç‰¹æ€§
ğŸ”¸ gemini-2.5-flash-lite-preview-09-2025ï¼š2025å¹´9æœˆé¢„è§ˆç‰ˆè½»é‡æ¨¡å‹ï¼Œå¿«é€Ÿå“åº”
ğŸ”¸ gemini-2.5-flashï¼šæœ€æ–°Flashæ¨¡å‹ï¼Œé€Ÿåº¦å’Œè´¨é‡å¹³è¡¡
ğŸ”¸ gemini-2.5-flash-liteï¼šè½»é‡ç‰ˆ2.5æ¨¡å‹ï¼Œå¿«é€Ÿå“åº” (é»˜è®¤æ¨è)
ğŸ”¸ gemini-2.0-flashï¼šæ–°ä¸€ä»£Flashæ¨¡å‹ï¼Œæ€§èƒ½æå‡

ğŸ’¡ Geminiåœ¨å¤šæ¨¡æ€ç†è§£ã€ä»£ç è¯†åˆ«ã€å›¾è¡¨åˆ†æã€åˆ›æ„ç”Ÿæˆæ–¹é¢è¡¨ç°ä¼˜å¼‚
ğŸ’­ 2.5ç³»åˆ—æ”¯æŒæ·±åº¦æ€è€ƒåŠŸèƒ½ï¼Œå¯è®¾ç½®æ¨ç†åŠªåŠ›çº§åˆ«
ğŸ“– å‚è€ƒæ–‡æ¡£ï¼šhttps://ai.google.dev/gemini-api/docs/openai"""
        
        # é‡å»ºoptionalå­—å…¸ä»¥ç¡®ä¿å‚æ•°é¡ºåº
        new_optional = {}
        
        # ä¿æŒåŸæœ‰å‚æ•°é¡ºåº
        new_optional["temperature"] = base_types["optional"]["temperature"]
        new_optional["top_p"] = base_types["optional"]["top_p"]
        
        # æ’å…¥å›¾åƒè´¨é‡å‚æ•°
        new_optional["image_quality"] = (["auto", "low", "high"], {
            "default": "auto",
            "tooltip": "å›¾åƒå¤„ç†è´¨é‡ï¼šauto(è‡ªåŠ¨é€‰æ‹©), low(ä½è´¨é‡ï¼Œé€Ÿåº¦å¿«), high(é«˜è´¨é‡ï¼Œç²¾åº¦é«˜)"
        })
        
        # æ·»åŠ Geminiç‰¹æœ‰çš„æ¨ç†åŠªåŠ›å‚æ•°
        new_optional["reasoning_effort"] = (["none", "low", "medium", "high"], {
            "default": "none",
            "tooltip": "æ¨ç†æ·±åº¦ï¼šnone(å…³é—­), low(è½»åº¦æ€è€ƒ), medium(ä¸­åº¦æ€è€ƒ), high(æ·±åº¦æ€è€ƒ) - Gemini 2.5ç³»åˆ—ç‰¹æœ‰åŠŸèƒ½"
        })
        
        # æœ€åæ·»åŠ clear_historyå‚æ•°
        new_optional["clear_history"] = base_types["optional"]["clear_history"]
        
        # æ›¿æ¢åŸæœ‰çš„optionalå­—å…¸
        base_types["optional"] = new_optional
        
        # è°ƒæ•´Geminiè§†è§‰çš„é»˜è®¤å€¼
        base_types["optional"]["temperature"][1]["default"] = 0.4  # Geminiå»ºè®®ç¨é«˜çš„æ¸©åº¦
        base_types["optional"]["top_p"][1]["default"] = 0.95  # Geminiæ”¯æŒæ›´é«˜çš„top_på€¼
        base_types["required"]["history"][1]["default"] = 6  # Geminiæ”¯æŒè¾ƒé•¿çš„å¯¹è¯å†å²
        base_types["required"]["max_tokens"][1]["default"] = 4096  # Geminiå¯ä»¥ç”Ÿæˆè¾ƒé•¿çš„å›ç­”
        base_types["required"]["model"][1]["default"] = "gemini-2.5-flash-lite"  # è®¾ç½®é»˜è®¤æ¨¡å‹ï¼ˆè½»é‡çº§2.5ï¼‰
        
        return base_types
    
    def generate_response(self, image, text_input: str, platform: str, model: str, max_tokens: int, history: int,
                         temperature: float = 0.4, top_p: float = 0.95, 
                         image_quality: str = "auto", reasoning_effort: str = "none", clear_history: bool = False):
        """
        ç”Ÿæˆè§†è§‰å“åº”ï¼Œæ·»åŠ å›¾åƒè´¨é‡å‚æ•°æ”¯æŒ
        """
        try:
            # æ¸…é™¤å†å²è®°å½•
            if clear_history:
                self.conversation_manager.clear_all()
            
            # éªŒè¯è¾“å…¥å‚æ•°
            is_valid, error_msg = self._validate_inputs(platform, model)
            if not is_valid:
                return (error_msg, "å‚æ•°é”™è¯¯", 0)
            
            # è·å–å¹³å°é…ç½®å’Œé€‚é…å™¨
            platform_config = self.PLATFORM_CONFIGS[platform]
            adapter = self._get_platform_adapter(platform)
            
            # è·å–APIå¯†é’¥
            api_key = self.api_key_manager.get_api_key(platform_config)
            if not api_key:
                error_msg = f"""é”™è¯¯ï¼šæœªæä¾›{platform}çš„APIå¯†é’¥ã€‚è¯·å°è¯•ä»¥ä¸‹æ–¹æ³•ä¹‹ä¸€ï¼š

1. è®¾ç½®ç¯å¢ƒå˜é‡ï¼š{platform_config.api_key_env}
2. åœ¨ğŸ¨QINGè®¾ç½®ä¸­é…ç½®APIå¯†é’¥
3. ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶è®¾ç½®å¯†é’¥

è·å–Gemini APIå¯†é’¥ï¼šhttps://aistudio.google.com/app/apikey

è¯·é…ç½®åé‡è¯•ã€‚"""
                return (error_msg, "APIå¯†é’¥ç¼ºå¤±", 0)
            
            # è·å–æˆ–åˆ›å»ºå®¢æˆ·ç«¯
            client = self.client_manager.get_or_create_client(platform_config, api_key)
            
            # ç®¡ç†å¯¹è¯å†å²
            conversation_key = self.conversation_manager.get_conversation_key(
                platform_config.platform_key, model
            )
            
            # å‡†å¤‡è§†è§‰æ¶ˆæ¯
            messages = self._prepare_vision_messages(image, text_input, conversation_key)
            
            # é™åˆ¶å†å²é•¿åº¦
            self.conversation_manager.limit_history(conversation_key, history)
            
            # å‡†å¤‡åŸºç¡€APIå‚æ•°
            base_params = self._prepare_base_params(
                adapter.get_api_model_name(model),
                messages,
                adapter.apply_token_limit(max_tokens),
                temperature,
                top_p
            )
            
            # é€šè¿‡é€‚é…å™¨å‡†å¤‡æœ€ç»ˆå‚æ•°ï¼ˆåŒ…å«å›¾åƒè´¨é‡å’Œæ¨ç†åŠªåŠ›ï¼‰
            final_params = adapter.prepare_api_params(
                base_params, 
                image_quality=image_quality,
                reasoning_effort=reasoning_effort
            )
            
            # è°ƒç”¨API
            response = client.chat.completions.create(**final_params)
            
            # å¤„ç†å“åº”
            reply, usage_info = self._handle_api_response(response, conversation_key)
            
            # ç”Ÿæˆå¯¹è¯ä¿¡æ¯
            reasoning_info = f" | æ¨ç†: {reasoning_effort}" if reasoning_effort != "none" else ""
            conversation_info = f"å¹³å°: {platform} | æ¨¡å‹: {model} | å†å²è½®æ•°: {len(messages)//2} | å›¾åƒè´¨é‡: {image_quality}{reasoning_info} | æ€»Tokens: {usage_info['total_tokens']} (è¾“å…¥: {usage_info['prompt_tokens']}, è¾“å‡º: {usage_info['completion_tokens']}, é™åˆ¶: {max_tokens})"
            
            return (reply, conversation_info, usage_info['total_tokens'])
            
        except Exception as e:
            error_message = f"{self.NODE_NAME} APIè°ƒç”¨å¤±è´¥ ({platform}): {str(e)}"
            return (error_message, "é”™è¯¯çŠ¶æ€", 0)


# ComfyUIèŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "GeminiVisionAPI": GeminiVisionAPI
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "GeminiVisionAPI": "Gemini_è§†è§‰ä¸¨API"
}
