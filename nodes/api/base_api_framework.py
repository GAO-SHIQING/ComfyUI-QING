# -*- coding: utf-8 -*-
"""
é€šç”¨APIèŠ‚ç‚¹åŸºç¡€æ¡†æ¶
ä¸ºæ‰€æœ‰AIæ¨¡å‹APIèŠ‚ç‚¹æä¾›ç»Ÿä¸€çš„åŸºç¡€æ¶æ„
æ”¯æŒå¤šå¹³å°ã€å¤šæ¨¡å‹çš„ç»Ÿä¸€ç®¡ç†
"""

import os
from typing import Optional, List, Dict, Any, Tuple, Type
from pathlib import Path
from dataclasses import dataclass, field
from abc import ABC, abstractmethod
from enum import Enum

try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False


class APIType(Enum):
    """APIç±»å‹æšä¸¾"""
    LANGUAGE = "language"
    VISION = "vision"
    MULTIMODAL = "multimodal"


@dataclass
class PlatformConfig:
    """å¹³å°é…ç½®æ•°æ®ç±»"""
    name: str
    base_url: str
    api_key_env: str
    config_key: str
    platform_key: str
    models: List[str]
    model_mapping: Dict[str, str]
    max_tokens_limit: Optional[int] = None
    supports_repetition_penalty: bool = False
    supports_frequency_penalty: bool = True
    supports_presence_penalty: bool = False
    custom_params: Dict[str, Any] = field(default_factory=dict)


class BasePlatformAdapter(ABC):
    """å¹³å°é€‚é…å™¨æŠ½è±¡åŸºç±»"""
    
    def __init__(self, config: PlatformConfig):
        self.config = config
    
    @abstractmethod
    def prepare_api_params(self, base_params: Dict[str, Any], **kwargs) -> Dict[str, Any]:
        """å‡†å¤‡APIè°ƒç”¨å‚æ•°"""
        pass
    
    def validate_model(self, model: str) -> bool:
        """éªŒè¯æ¨¡å‹æ˜¯å¦æ”¯æŒ"""
        return model in self.config.models
    
    def get_api_model_name(self, model: str) -> str:
        """è·å–APIè°ƒç”¨æ—¶çš„æ¨¡å‹åç§°"""
        return self.config.model_mapping.get(model, model.lower())
    
    def apply_token_limit(self, max_tokens: int) -> int:
        """åº”ç”¨å¹³å°tokené™åˆ¶"""
        if self.config.max_tokens_limit:
            return min(max_tokens, self.config.max_tokens_limit)
        return max_tokens
    
    def handle_repetition_penalty(self, params: Dict[str, Any], repetition_penalty: float) -> Dict[str, Any]:
        """å¤„ç†é‡å¤æƒ©ç½šå‚æ•°"""
        if repetition_penalty == 1.0:
            return params
            
        if self.config.supports_repetition_penalty:
            params["repetition_penalty"] = repetition_penalty
        elif self.config.supports_frequency_penalty:
            params["frequency_penalty"] = (repetition_penalty - 1.0) * 0.5
        
        return params
    
    def handle_image_quality(self, params: Dict[str, Any], image_quality: str) -> Dict[str, Any]:
        """å¤„ç†å›¾åƒè´¨é‡å‚æ•°ï¼ˆè§†è§‰èŠ‚ç‚¹ä¸“ç”¨ï¼‰"""
        if image_quality != 'auto':
            params["image_quality"] = image_quality
        return params


class APIKeyManager:
    """APIå¯†é’¥ç®¡ç†å™¨ - é€šç”¨ç‰ˆæœ¬"""
    
    @staticmethod
    def get_api_key(platform_config: PlatformConfig) -> str:
        """è·å–APIå¯†é’¥ï¼ˆæ”¯æŒå¤šå¹³å°ï¼‰"""
        final_api_key = ""
        config_key = platform_config.config_key

        # ç­–ç•¥1: ä»ç¯å¢ƒå˜é‡è·å–
        final_api_key = os.getenv(platform_config.api_key_env, '')

        # ç­–ç•¥2: ä»ğŸ¨QINGé…ç½®ç³»ç»Ÿè·å–ï¼ˆæ”¯æŒå¤šå¹³å°ï¼‰
        if not final_api_key:
            try:
                # ç›´æ¥ä»settings_approachè·å–ï¼Œé¿å…å¤æ‚çš„å¯¼å…¥é“¾
                from .utils.settings_approach import get_qing_api_key_improved
                final_api_key = get_qing_api_key_improved(config_key)
            except ImportError:
                pass

        # ç­–ç•¥3: ä»ä¸´æ—¶æ–‡ä»¶è·å–ï¼ˆå…¼å®¹æ€§ï¼‰
        if not final_api_key:
            try:
                import tempfile
                temp_file = Path(tempfile.gettempdir()) / f"qing_{config_key}_temp.txt"
                if temp_file.exists():
                    with open(temp_file, 'r', encoding='utf-8') as f:
                        temp_key = f.read().strip()
                        if temp_key:
                            final_api_key = temp_key
            except Exception:
                pass

        return final_api_key


class ConversationManager:
    """å¯¹è¯å†å²ç®¡ç†å™¨ - é€šç”¨ç‰ˆæœ¬"""
    
    def __init__(self):
        self.conversation_history: Dict[str, List[Dict[str, str]]] = {}
    
    def get_conversation_key(self, platform_key: str, model: str, user_id: str = "default") -> str:
        """ç”Ÿæˆå¯¹è¯é”®"""
        return f"{platform_key}_{model}_{user_id}"
    
    def add_message(self, conversation_key: str, role: str, content: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°å†å²"""
        if conversation_key not in self.conversation_history:
            self.conversation_history[conversation_key] = []
        
        self.conversation_history[conversation_key].append({
            "role": role, 
            "content": content
        })
    
    def get_history(self, conversation_key: str) -> List[Dict[str, str]]:
        """è·å–å¯¹è¯å†å²"""
        return self.conversation_history.get(conversation_key, [])
    
    def limit_history(self, conversation_key: str, max_rounds: int):
        """é™åˆ¶å†å²é•¿åº¦"""
        if conversation_key in self.conversation_history:
            history = self.conversation_history[conversation_key]
            if len(history) > max_rounds * 2:
                self.conversation_history[conversation_key] = history[-(max_rounds * 2):]
    
    def clear_all(self):
        """æ¸…é™¤æ‰€æœ‰å†å²"""
        self.conversation_history.clear()
    
    def clear_conversation(self, conversation_key: str):
        """æ¸…é™¤ç‰¹å®šå¯¹è¯å†å²"""
        if conversation_key in self.conversation_history:
            del self.conversation_history[conversation_key]


class ClientManager:
    """APIå®¢æˆ·ç«¯ç®¡ç†å™¨ - é€šç”¨ç‰ˆæœ¬"""
    
    def __init__(self):
        self._clients = {}
    
    def get_or_create_client(self, platform_config: PlatformConfig, api_key: str):
        """è·å–æˆ–åˆ›å»ºAPIå®¢æˆ·ç«¯ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        client_key = f"{platform_config.platform_key}_{api_key[:10]}"
        
        if client_key not in self._clients:
            try:
                from openai import OpenAI
                self._clients[client_key] = OpenAI(
                    base_url=platform_config.base_url,
                    api_key=api_key
                )
            except ImportError:
                raise ImportError("é”™è¯¯ï¼šæœªå®‰è£…openaiåº“ã€‚è¯·è¿è¡Œï¼špip install openai")
        
        return self._clients[client_key]
    
    def clear_clients(self):
        """æ¸…é™¤æ‰€æœ‰å®¢æˆ·ç«¯ç¼“å­˜"""
        self._clients.clear()


class BaseAPINode(ABC):
    """
    APIèŠ‚ç‚¹åŸºç±»
    ä¸ºæ‰€æœ‰AIæ¨¡å‹APIèŠ‚ç‚¹æä¾›ç»Ÿä¸€çš„åŸºç¡€åŠŸèƒ½
    """
    
    # æ ‡è®°ä¸ºåŸºç±»ï¼Œä¸åº”è¯¥è¢«ComfyUIæ³¨å†Œä¸ºèŠ‚ç‚¹
    _IS_BASE_CLASS = True
    
    # å­ç±»éœ€è¦å®šä¹‰çš„å±æ€§
    API_TYPE: APIType = APIType.LANGUAGE
    NODE_NAME: str = "BaseAPI"
    DISPLAY_NAME: str = "Base API"
    CATEGORY: str = "ğŸ¨QING/APIè°ƒç”¨"
    
    # å¹³å°é…ç½®å’Œé€‚é…å™¨æ˜ å°„ - å­ç±»éœ€è¦é‡å†™
    PLATFORM_CONFIGS: Dict[str, PlatformConfig] = {}
    PLATFORM_ADAPTERS: Dict[str, Type[BasePlatformAdapter]] = {}
    
    def __init__(self):
        """åˆå§‹åŒ–èŠ‚ç‚¹"""
        self.conversation_manager = ConversationManager()
        self.api_key_manager = APIKeyManager()
        self.client_manager = ClientManager()
    
    @classmethod
    def get_all_models(cls) -> List[str]:
        """è·å–æ‰€æœ‰æ”¯æŒçš„æ¨¡å‹ï¼ˆç±»æ–¹æ³•ï¼Œé¿å…å®ä¾‹åŒ–ï¼‰"""
        models = []
        for config in cls.PLATFORM_CONFIGS.values():
            models.extend(config.models)
        return list(set(models))  # å»é‡
    
    @property
    def all_models(self) -> List[str]:
        """è·å–æ‰€æœ‰æ”¯æŒçš„æ¨¡å‹ï¼ˆå®ä¾‹æ–¹æ³•ï¼Œå‘åå…¼å®¹ï¼‰"""
        return self.get_all_models()
    
    @classmethod
    @abstractmethod
    def get_input_types(cls) -> Dict[str, Any]:
        """è·å–è¾“å…¥ç±»å‹ - å­ç±»å¿…é¡»å®ç°"""
        pass
    
    @classmethod
    def INPUT_TYPES(cls):
        """ComfyUIæ ‡å‡†æ¥å£"""
        return cls.get_input_types()
    
    def _validate_inputs(self, platform: str, model: str) -> Tuple[bool, str]:
        """éªŒè¯è¾“å…¥å‚æ•°"""
        # éªŒè¯å¹³å°
        if platform not in self.PLATFORM_CONFIGS:
            return False, f"é”™è¯¯ï¼šä¸æ”¯æŒçš„å¹³å° '{platform}'"
        
        # éªŒè¯æ¨¡å‹
        platform_config = self.PLATFORM_CONFIGS[platform]
        if model not in platform_config.models:
            available_models = ", ".join(platform_config.models)
            return False, f"âŒ æ¨¡å‹å…¼å®¹æ€§é”™è¯¯\n\nå¹³å° '{platform}' ä¸æ”¯æŒæ¨¡å‹ '{model}'\n\nâœ… è¯¥å¹³å°æ”¯æŒçš„æ¨¡å‹ï¼š\n{available_models}"
        
        return True, ""
    
    def _get_platform_adapter(self, platform: str) -> BasePlatformAdapter:
        """è·å–å¹³å°é€‚é…å™¨"""
        platform_config = self.PLATFORM_CONFIGS[platform]
        adapter_class = self.PLATFORM_ADAPTERS[platform]
        return adapter_class(platform_config)
    
    def _prepare_base_params(self, model: str, messages: List[Dict[str, str]], 
                           max_tokens: int, temperature: float, top_p: float) -> Dict[str, Any]:
        """å‡†å¤‡åŸºç¡€APIå‚æ•°"""
        return {
            "model": model,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature,
            "top_p": top_p
        }
    
    def _handle_api_response(self, response, conversation_key: str) -> Tuple[str, Dict[str, Any]]:
        """å¤„ç†APIå“åº”"""
        # æå–å›å¤
        reply = response.choices[0].message.content
        
        # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°å†å²
        self.conversation_manager.add_message(conversation_key, "assistant", reply)
        
        # è®¡ç®—tokenä½¿ç”¨æƒ…å†µ
        usage_info = {}
        if hasattr(response, 'usage') and response.usage:
            usage_info = {
                'total_tokens': response.usage.total_tokens,
                'prompt_tokens': getattr(response.usage, 'prompt_tokens', 0),
                'completion_tokens': getattr(response.usage, 'completion_tokens', 0)
            }
        else:
            usage_info = {'total_tokens': 0, 'prompt_tokens': 0, 'completion_tokens': 0}
        
        return reply, usage_info
    
    @abstractmethod
    def generate_response(self, **kwargs) -> Tuple[str, str, int]:
        """ç”Ÿæˆå“åº” - å­ç±»å¿…é¡»å®ç°"""
        pass
    
    @classmethod
    def IS_CHANGED(cls, **kwargs):
        """ComfyUIç¼“å­˜æ§åˆ¶"""
        return float("nan")


class BaseLanguageAPINode(BaseAPINode):
    """
    è¯­è¨€æ¨¡å‹APIèŠ‚ç‚¹åŸºç±»
    ä¸ºè¯­è¨€æ¨¡å‹æä¾›æ ‡å‡†çš„è¾“å…¥è¾“å‡ºæ¥å£
    """
    
    # æ ‡è®°ä¸ºåŸºç±»ï¼Œä¸åº”è¯¥è¢«ComfyUIæ³¨å†Œä¸ºèŠ‚ç‚¹
    _IS_BASE_CLASS = True
    
    API_TYPE = APIType.LANGUAGE
    
    @classmethod
    def get_input_types(cls) -> Dict[str, Any]:
        """è¯­è¨€æ¨¡å‹çš„æ ‡å‡†è¾“å…¥ç±»å‹"""
        return {
            "required": {
                "text_input": ("STRING", {
                    "default": "è¯·å¸®æˆ‘åˆ†æä¸€ä¸‹è¿™ä¸ªé—®é¢˜ï¼Œå¹¶æä¾›è¯¦ç»†çš„è§£å†³æ–¹æ¡ˆã€‚",
                    "multiline": True,
                    "tooltip": "è¾“å…¥è¦å‘é€ç»™AIæ¨¡å‹çš„æ–‡æœ¬å†…å®¹"
                }),
                "platform": (list(cls.PLATFORM_CONFIGS.keys()), {
                    "default": list(cls.PLATFORM_CONFIGS.keys())[0] if cls.PLATFORM_CONFIGS else "æœªé…ç½®",
                    "tooltip": "é€‰æ‹©APIæœåŠ¡æä¾›å•†"
                }),
                "model": (cls.get_all_models(), {
                    "default": cls.get_all_models()[0] if cls.get_all_models() else "æœªé…ç½®",
                    "tooltip": "é€‰æ‹©è¦ä½¿ç”¨çš„AIæ¨¡å‹"
                }),
                "max_tokens": ("INT", {
                    "default": 4096,
                    "min": 1,
                    "max": 32768,
                    "step": 1,
                    "tooltip": "æ¨¡å‹ç”Ÿæˆæ–‡æœ¬æ—¶æœ€å¤šèƒ½ä½¿ç”¨çš„tokenæ•°é‡"
                }),
                "history": ("INT", {
                    "default": 20,
                    "min": 1,
                    "max": 40,
                    "step": 1,
                    "tooltip": "ä¿æŒçš„å†å²å¯¹è¯è½®æ•°"
                }),
            },
            "optional": {
                "temperature": ("FLOAT", {
                    "default": 0.7,
                    "min": 0.0,
                    "max": 2.0,
                    "step": 0.1,
                    "tooltip": "æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§"
                }),
                "top_p": ("FLOAT", {
                    "default": 0.9,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.05,
                    "tooltip": "æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„å¤šæ ·æ€§"
                }),
                "repetition_penalty": ("FLOAT", {
                    "default": 1.1,
                    "min": 1.0,
                    "max": 1.3,
                    "step": 0.05,
                    "tooltip": "æ§åˆ¶é‡å¤æ–‡æœ¬çš„æƒ©ç½šç¨‹åº¦"
                }),
                "clear_history": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦æ¸…é™¤å†å²å¯¹è¯è®°å½•"
                }),
            }
        }
    
    # æ ‡å‡†è¿”å›ç±»å‹
    RETURN_TYPES = ("STRING", "STRING", "INT")
    RETURN_NAMES = ("generated_text", "conversation_info", "total_tokens")
    FUNCTION = "generate_response"
    OUTPUT_NODE = False
    
    def generate_response(self, text_input: str, platform: str, model: str, max_tokens: int, history: int,
                         temperature: Optional[float] = 0.7, top_p: Optional[float] = 0.9, 
                         repetition_penalty: Optional[float] = 1.1, clear_history: Optional[bool] = False):
        """
        ç”Ÿæˆæ–‡æœ¬å“åº”çš„é€šç”¨å®ç°
        """
        try:
            # æ¸…é™¤å†å²è®°å½•
            if clear_history:
                self.conversation_manager.clear_all()
            
            # éªŒè¯è¾“å…¥å‚æ•°
            is_valid, error_msg = self._validate_inputs(platform, model)
            if not is_valid:
                return (error_msg, "å‚æ•°é”™è¯¯", 0)
            
            # è·å–å¹³å°é…ç½®å’Œé€‚é…å™¨
            platform_config = self.PLATFORM_CONFIGS[platform]
            adapter = self._get_platform_adapter(platform)
            
            # è·å–APIå¯†é’¥
            api_key = self.api_key_manager.get_api_key(platform_config)
            if not api_key:
                error_msg = f"""é”™è¯¯ï¼šæœªæä¾›{platform}çš„APIå¯†é’¥ã€‚è¯·å°è¯•ä»¥ä¸‹æ–¹æ³•ä¹‹ä¸€ï¼š

1. è®¾ç½®ç¯å¢ƒå˜é‡ï¼š{platform_config.api_key_env}
2. åœ¨ğŸ¨QINGè®¾ç½®ä¸­é…ç½®APIå¯†é’¥
3. ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶è®¾ç½®å¯†é’¥

è¯·é…ç½®åé‡è¯•ã€‚"""
                return (error_msg, "APIå¯†é’¥ç¼ºå¤±", 0)
            
            # è·å–æˆ–åˆ›å»ºå®¢æˆ·ç«¯
            client = self.client_manager.get_or_create_client(platform_config, api_key)
            
            # ç®¡ç†å¯¹è¯å†å²
            conversation_key = self.conversation_manager.get_conversation_key(
                platform_config.platform_key, model
            )
            
            # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
            self.conversation_manager.add_message(conversation_key, "user", text_input)
            
            # é™åˆ¶å†å²é•¿åº¦
            self.conversation_manager.limit_history(conversation_key, history)
            
            # è·å–å½“å‰å†å²
            current_history = self.conversation_manager.get_history(conversation_key)
            
            # å‡†å¤‡åŸºç¡€APIå‚æ•°
            base_params = self._prepare_base_params(
                adapter.get_api_model_name(model),
                current_history,
                adapter.apply_token_limit(max_tokens),
                temperature,
                top_p
            )
            
            # ä½¿ç”¨é€‚é…å™¨å‡†å¤‡æœ€ç»ˆå‚æ•°
            api_params = adapter.prepare_api_params(
                base_params,
                model=model,
                repetition_penalty=repetition_penalty
            )
            
            # è°ƒç”¨API
            response = client.chat.completions.create(**api_params)
            
            # å¤„ç†å“åº”
            reply, usage_info = self._handle_api_response(response, conversation_key)
            
            # ç”Ÿæˆå¯¹è¯ä¿¡æ¯
            conversation_info = f"å¹³å°: {platform} | æ¨¡å‹: {model} | å†å²è½®æ•°: {len(current_history)//2} | æ€»Tokens: {usage_info['total_tokens']} (è¾“å…¥: {usage_info['prompt_tokens']}, è¾“å‡º: {usage_info['completion_tokens']}, é™åˆ¶: {max_tokens})"
            
            return (reply, conversation_info, usage_info['total_tokens'])
            
        except Exception as e:
            error_message = f"{self.NODE_NAME} APIè°ƒç”¨å¤±è´¥ ({platform}): {str(e)}"
            return (error_message, "é”™è¯¯çŠ¶æ€", 0)


class BaseVisionAPINode(BaseAPINode):
    """
    è§†è§‰æ¨¡å‹APIèŠ‚ç‚¹åŸºç±»
    ä¸ºè§†è§‰æ¨¡å‹æä¾›æ ‡å‡†çš„è¾“å…¥è¾“å‡ºæ¥å£
    """
    
    # æ ‡è®°ä¸ºåŸºç±»ï¼Œä¸åº”è¯¥è¢«ComfyUIæ³¨å†Œä¸ºèŠ‚ç‚¹
    _IS_BASE_CLASS = True
    
    API_TYPE = APIType.VISION
    
    @classmethod
    def get_input_types(cls) -> Dict[str, Any]:
        """è§†è§‰æ¨¡å‹çš„æ ‡å‡†è¾“å…¥ç±»å‹"""
        return {
            "required": {
                "image": ("IMAGE", {
                    "tooltip": "è¾“å…¥è¦åˆ†æçš„å›¾åƒ"
                }),
                "text_input": ("STRING", {
                    "default": "è¯·æè¿°è¿™å¼ å›¾ç‰‡çš„å†…å®¹ã€‚",
                    "multiline": True,
                    "tooltip": "è¾“å…¥è¦å‘é€ç»™AIè§†è§‰æ¨¡å‹çš„æ–‡æœ¬é—®é¢˜"
                }),
                "platform": (list(cls.PLATFORM_CONFIGS.keys()), {
                    "default": list(cls.PLATFORM_CONFIGS.keys())[0] if cls.PLATFORM_CONFIGS else "æœªé…ç½®",
                    "tooltip": "é€‰æ‹©APIæœåŠ¡æä¾›å•†"
                }),
                "model": (cls.get_all_models(), {
                    "default": cls.get_all_models()[0] if cls.get_all_models() else "æœªé…ç½®",
                    "tooltip": "é€‰æ‹©è¦ä½¿ç”¨çš„AIè§†è§‰æ¨¡å‹"
                }),
                "max_tokens": ("INT", {
                    "default": 4096,
                    "min": 1,
                    "max": 32768,
                    "step": 1,
                    "tooltip": "æ¨¡å‹ç”Ÿæˆæ–‡æœ¬æ—¶æœ€å¤šèƒ½ä½¿ç”¨çš„tokenæ•°é‡"
                }),
                "history": ("INT", {
                    "default": 10,
                    "min": 1,
                    "max": 25,
                    "step": 1,
                    "tooltip": "ä¿æŒçš„å†å²å¯¹è¯è½®æ•°"
                }),
            },
            "optional": {
                "temperature": ("FLOAT", {
                    "default": 0.7,
                    "min": 0.0,
                    "max": 2.0,
                    "step": 0.1,
                    "tooltip": "æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§"
                }),
                "top_p": ("FLOAT", {
                    "default": 0.9,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.05,
                    "tooltip": "æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„å¤šæ ·æ€§"
                }),
                "image_quality": (["auto", "low", "high"], {
                    "default": "auto",
                    "tooltip": "å›¾åƒå¤„ç†è´¨é‡ï¼šauto(è‡ªåŠ¨é€‰æ‹©), low(ä½è´¨é‡ï¼Œé€Ÿåº¦å¿«), high(é«˜è´¨é‡ï¼Œç²¾åº¦é«˜)"
                }),
                "clear_history": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦æ¸…é™¤å†å²å¯¹è¯è®°å½•"
                }),
            }
        }
    
    # æ ‡å‡†è¿”å›ç±»å‹
    RETURN_TYPES = ("STRING", "STRING", "INT")
    RETURN_NAMES = ("generated_text", "conversation_info", "total_tokens")
    FUNCTION = "generate_response"
    OUTPUT_NODE = False
    
    def _image_to_base64(self, image) -> str:
        """å°†å›¾åƒè½¬æ¢ä¸ºbase64æ ¼å¼"""
        try:
            # å¤„ç†ComfyUIçš„å›¾åƒæ ¼å¼
            if TORCH_AVAILABLE and isinstance(image, torch.Tensor):
                if image.dim() == 4:  # batch dimension
                    image = image.squeeze(0)
                if image.dim() == 3 and image.shape[0] in [1, 3, 4]:  # CHW format
                    image = image.permute(1, 2, 0)  # HWC format
                
                # ç¡®ä¿å€¼åœ¨0-255èŒƒå›´å†…
                if image.max() <= 1.0:
                    image = image * 255
                image = image.clamp(0, 255).byte()
                
                # è½¬æ¢ä¸ºPIL Image
                import numpy as np
                from PIL import Image
                image_np = image.cpu().numpy()
                if image_np.shape[2] == 1:  # ç°åº¦å›¾
                    image_pil = Image.fromarray(image_np.squeeze(), mode='L')
                elif image_np.shape[2] == 3:  # RGB
                    image_pil = Image.fromarray(image_np, mode='RGB')
                elif image_np.shape[2] == 4:  # RGBA
                    image_pil = Image.fromarray(image_np, mode='RGBA')
                else:
                    raise ValueError(f"ä¸æ”¯æŒçš„å›¾åƒé€šé“æ•°: {image_np.shape[2]}")
            else:
                image_pil = image
            
            # è½¬æ¢ä¸ºbase64
            import base64
            from io import BytesIO
            buffer = BytesIO()
            image_pil.save(buffer, format='PNG')
            image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
            
            return f"data:image/png;base64,{image_base64}"
            
        except Exception as e:
            raise ValueError(f"å›¾åƒè½¬æ¢å¤±è´¥: {str(e)}")
    
    def _prepare_vision_messages(self, image, text_input: str, conversation_key: str) -> List[Dict[str, Any]]:
        """å‡†å¤‡è§†è§‰æ¨¡å‹çš„æ¶ˆæ¯æ ¼å¼"""
        # è½¬æ¢å›¾åƒä¸ºbase64
        image_base64 = self._image_to_base64(image)
        
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯ï¼ˆåŒ…å«å›¾åƒå’Œæ–‡æœ¬ï¼‰
        user_message = {
            "role": "user",
            "content": [
                {
                    "type": "text",
                    "text": text_input
                },
                {
                    "type": "image_url",
                    "image_url": {
                        "url": image_base64
                    }
                }
            ]
        }
        
        self.conversation_manager.add_message(conversation_key, "user", user_message["content"])
        
        # è·å–å†å²æ¶ˆæ¯
        return self.conversation_manager.get_history(conversation_key)
    
    def generate_response(self, image, text_input: str, platform: str, model: str, max_tokens: int, history: int,
                         temperature: Optional[float] = 0.7, top_p: Optional[float] = 0.9, 
                         image_quality: Optional[str] = "auto", clear_history: Optional[bool] = False):
        """
        ç”Ÿæˆè§†è§‰å“åº”çš„é€šç”¨å®ç°
        """
        try:
            # æ¸…é™¤å†å²è®°å½•
            if clear_history:
                self.conversation_manager.clear_all()
            
            # éªŒè¯è¾“å…¥å‚æ•°
            is_valid, error_msg = self._validate_inputs(platform, model)
            if not is_valid:
                return (error_msg, "å‚æ•°é”™è¯¯", 0)
            
            # è·å–å¹³å°é…ç½®å’Œé€‚é…å™¨
            platform_config = self.PLATFORM_CONFIGS[platform]
            adapter = self._get_platform_adapter(platform)
            
            # è·å–APIå¯†é’¥
            api_key = self.api_key_manager.get_api_key(platform_config)
            if not api_key:
                error_msg = f"""é”™è¯¯ï¼šæœªæä¾›{platform}çš„APIå¯†é’¥ã€‚è¯·å°è¯•ä»¥ä¸‹æ–¹æ³•ä¹‹ä¸€ï¼š

1. è®¾ç½®ç¯å¢ƒå˜é‡ï¼š{platform_config.api_key_env}
2. åœ¨ğŸ¨QINGè®¾ç½®ä¸­é…ç½®APIå¯†é’¥
3. ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶è®¾ç½®å¯†é’¥

è¯·é…ç½®åé‡è¯•ã€‚"""
                return (error_msg, "APIå¯†é’¥ç¼ºå¤±", 0)
            
            # è·å–æˆ–åˆ›å»ºå®¢æˆ·ç«¯
            client = self.client_manager.get_or_create_client(platform_config, api_key)
            
            # ç®¡ç†å¯¹è¯å†å²
            conversation_key = self.conversation_manager.get_conversation_key(
                platform_config.platform_key, model
            )
            
            # å‡†å¤‡è§†è§‰æ¶ˆæ¯
            messages = self._prepare_vision_messages(image, text_input, conversation_key)
            
            # é™åˆ¶å†å²é•¿åº¦
            self.conversation_manager.limit_history(conversation_key, history)
            
            # å‡†å¤‡åŸºç¡€APIå‚æ•°
            base_params = self._prepare_base_params(
                adapter.get_api_model_name(model),
                messages,
                adapter.apply_token_limit(max_tokens),
                temperature,
                top_p
            )
            
            # ä½¿ç”¨é€‚é…å™¨å‡†å¤‡æœ€ç»ˆå‚æ•°ï¼ˆåŒ…å«å›¾åƒè´¨é‡ï¼‰
            api_params = adapter.prepare_api_params(base_params, model=model, image_quality=image_quality)
            
            # è°ƒç”¨API
            response = client.chat.completions.create(**api_params)
            
            # å¤„ç†å“åº”
            reply, usage_info = self._handle_api_response(response, conversation_key)
            
            # ç”Ÿæˆå¯¹è¯ä¿¡æ¯
            conversation_info = f"å¹³å°: {platform} | æ¨¡å‹: {model} | å†å²è½®æ•°: {len(messages)//2} | å›¾åƒè´¨é‡: {image_quality} | æ€»Tokens: {usage_info['total_tokens']} (è¾“å…¥: {usage_info['prompt_tokens']}, è¾“å‡º: {usage_info['completion_tokens']}, é™åˆ¶: {max_tokens})"
            
            return (reply, conversation_info, usage_info['total_tokens'])
            
        except Exception as e:
            error_message = f"{self.NODE_NAME} APIè°ƒç”¨å¤±è´¥ ({platform}): {str(e)}"
            return (error_message, "é”™è¯¯çŠ¶æ€", 0)


# å¯¼å‡ºåŸºç¡€ç±»ä¾›å…¶ä»–èŠ‚ç‚¹ä½¿ç”¨
__all__ = [
    'APIType',
    'PlatformConfig', 
    'BasePlatformAdapter',
    'APIKeyManager',
    'ConversationManager', 
    'ClientManager',
    'BaseAPINode',
    'BaseLanguageAPINode',
    'BaseVisionAPINode'
]
