# -*- coding: utf-8 -*-
"""
Kimi Language APIèŠ‚ç‚¹
è°ƒç”¨Kimiè¯­è¨€æ¨¡å‹APIè¿›è¡Œæ–‡æœ¬æ¨ç†
æ”¯æŒå¤šå¹³å°ï¼šæœˆä¹‹æš—é¢ã€ç«å±±å¼•æ“ã€é˜¿é‡Œäº‘ç™¾ç‚¼ã€ç¡…åŸºæµåŠ¨
"""

import os
from typing import Optional, List, Dict, Any
from pathlib import Path

# å®šä¹‰æœåŠ¡å¹³å°é…ç½®
SERVICE_PLATFORMS = {
    "æœˆä¹‹æš—é¢": {
        "base_url": "https://api.moonshot.cn/v1",
        "api_key_env": "MOONSHOT_API_KEY",
        "config_key": "moonshot_api_key",
        "platform_key": "moonshot",
        "models": ["kimi-k2-0905", "kimi-k2-0711", "kimi-k2-turbo"],
        "model_mapping": {
            "kimi-k2-0905": "kimi-k2-0905-preview",
            "kimi-k2-0711": "kimi-k2-0711-preview", 
            "kimi-k2-turbo": "kimi-k2-turbo-preview"
        }
    },
    "ç«å±±å¼•æ“": {
        "base_url": "https://ark.cn-beijing.volces.com/api/v3",
        "api_key_env": "VOLCENGINE_API_KEY",
        "config_key": "volcengine_api_key",
        "platform_key": "volcengine",
        "models": ["kimi-k2-0905"],
        "model_mapping": {
            "kimi-k2-0905": "kimi-k2-250905"
        }
    },
    "é˜¿é‡Œäº‘ç™¾ç‚¼": {
        "base_url": "https://dashscope.aliyuncs.com/compatible-mode/v1",
        "api_key_env": "DASHSCOPE_API_KEY", 
        "config_key": "dashscope_api_key",
        "platform_key": "dashscope",
        "models": ["kimi-k2-0905"],
        "model_mapping": {
            "kimi-k2-0905": "Moonshot-Kimi-K2-Instruct"
        }
    },
    "ç¡…åŸºæµåŠ¨": {
        "base_url": "https://api.siliconflow.cn/v1",
        "api_key_env": "SILICONFLOW_API_KEY",
        "config_key": "siliconflow_api_key",
        "platform_key": "siliconflow",
        "models": ["kimi-k2-0905"],
        "model_mapping": {
            "kimi-k2-0905": "moonshotai/Kimi-K2-Instruct-0905"
        }
    }
}

# æ‰€æœ‰æ”¯æŒçš„Kimiæ¨¡å‹ï¼ˆç”¨äºéªŒè¯ï¼‰
ALL_KIMI_MODELS = [
    "kimi-k2-0905", "kimi-k2-0711", "kimi-k2-turbo"
]


class KimiLanguageAPI:
    """
    Kimiè¯­è¨€æ¨¡å‹APIè°ƒç”¨èŠ‚ç‚¹
    æ”¯æŒå¤šä¸ªæœåŠ¡å¹³å°çš„Kimiæ¨¡å‹è°ƒç”¨
    """
    
    # ç±»å±æ€§
    SERVICE_PLATFORMS = SERVICE_PLATFORMS
    ALL_KIMI_MODELS = ALL_KIMI_MODELS
    
    def __init__(self):
        """åˆå§‹åŒ–èŠ‚ç‚¹"""
        self.conversation_history = {}
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "text_input": ("STRING", {
                    "default": "è¯·å¸®æˆ‘åˆ†æä¸€ä¸‹è¿™ä¸ªé—®é¢˜ï¼Œå¹¶æä¾›è¯¦ç»†çš„è§£å†³æ–¹æ¡ˆã€‚",
                    "multiline": True,
                    "tooltip": "è¾“å…¥è¦å‘é€ç»™Kimiæ¨¡å‹çš„æ–‡æœ¬å†…å®¹ï¼ŒKimiæ“…é•¿é•¿æ–‡æ¡£åˆ†æã€è”ç½‘æœç´¢å’Œå¤æ‚æ¨ç†"
                }),
                "platform": (list(cls.SERVICE_PLATFORMS.keys()), {
                    "default": "æœˆä¹‹æš—é¢",
                    "tooltip": "é€‰æ‹©Kimi APIæœåŠ¡æä¾›å•†"
                }),
                "model": (cls.ALL_KIMI_MODELS, {
                    "default": "kimi-k2-0905",
                    "tooltip": "é€‰æ‹©è¦ä½¿ç”¨çš„Kimiæ¨¡å‹\nğŸ“‹ æ¨¡å‹ç‰¹ç‚¹ï¼š\nğŸ”¸ kimi-k2-0905ï¼šæœ€æ–°ç‰ˆæœ¬ï¼Œ200ä¸‡å­—è¶…é•¿ä¸Šä¸‹æ–‡ï¼Œæ“…é•¿é•¿æ–‡æ¡£åˆ†æå’Œå¤æ‚æ¨ç†\nğŸ”¸ kimi-k2-0711ï¼šç¨³å®šç‰ˆæœ¬ï¼Œå¹³è¡¡æ€§èƒ½å’Œæˆæœ¬\nğŸ”¸ kimi-k2-turboï¼šå¿«é€Ÿå“åº”ç‰ˆæœ¬ï¼Œé€‚åˆç®€å•å¯¹è¯\nğŸ’¡ Kimiæ¨¡å‹å…·å¤‡è”ç½‘æœç´¢èƒ½åŠ›ï¼Œç‰¹åˆ«é€‚åˆéœ€è¦å®æ—¶ä¿¡æ¯çš„ä»»åŠ¡"
                }),
                "max_tokens": ("INT", {
                    "default": 4096,
                    "min": 1,
                    "max": 32768,
                    "step": 1,
                    "tooltip": "æ¨¡å‹ç”Ÿæˆæ–‡æœ¬æ—¶æœ€å¤šèƒ½ä½¿ç”¨çš„tokenæ•°é‡ï¼ŒKimiæ”¯æŒè¶…é•¿ä¸Šä¸‹æ–‡ï¼Œå»ºè®®è¾ƒé«˜å€¼ä»¥å‘æŒ¥é•¿æ–‡æœ¬ä¼˜åŠ¿"
                }),
                "history": ("INT", {
                    "default": 12,
                    "min": 1,
                    "max": 25,
                    "step": 1,
                    "tooltip": "ä¿æŒçš„å†å²å¯¹è¯è½®æ•°ï¼ŒKimiå…·å¤‡è¶…é•¿ä¸Šä¸‹æ–‡èƒ½åŠ›ï¼Œæ”¯æŒæ›´å¤šè½®æ¬¡çš„æ·±åº¦å¯¹è¯"
                }),
            },
            "optional": {
                "temperature": ("FLOAT", {
                    "default": 0.8,
                    "min": 0.0,
                    "max": 2.0,
                    "step": 0.1,
                    "tooltip": "æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§ï¼ŒKimiåœ¨è¾ƒé«˜æ¸©åº¦ä¸‹èƒ½å±•ç°æ›´å¥½çš„åˆ›é€ æ€§å’Œåˆ†ææ·±åº¦"
                }),
                "top_p": ("FLOAT", {
                    "default": 0.95,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.1,
                    "tooltip": "æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„å¤šæ ·æ€§ï¼ŒKimiåœ¨é«˜top_på€¼ä¸‹èƒ½æä¾›æ›´ä¸°å¯Œçš„åˆ†æè§†è§’"
                }),
                "clear_history": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦æ¸…é™¤å†å²å¯¹è¯è®°å½•"
                }),
            }
        }
    
    RETURN_TYPES = ("STRING", "STRING", "INT")
    RETURN_NAMES = ("generated_text", "conversation_info", "total_tokens")
    FUNCTION = "generate_text"
    CATEGORY = "ğŸ¨QING/APIè°ƒç”¨"
    OUTPUT_NODE = False
    
    def _get_api_key(self, platform_config: Dict[str, str]) -> str:
        """è·å–APIå¯†é’¥ï¼ˆæ”¯æŒå¤šå¹³å°ï¼‰"""
        final_api_key = ""
        config_key = platform_config["config_key"]

        # ç­–ç•¥1: ä»ç¯å¢ƒå˜é‡è·å–
        final_api_key = os.getenv(platform_config["api_key_env"], '')

        # ç­–ç•¥2: ä»ğŸ¨QINGé…ç½®ç³»ç»Ÿè·å–ï¼ˆæ”¯æŒå¤šå¹³å°ï¼‰
        if not final_api_key:
            try:
                from .config_server import get_api_key_by_platform
                final_api_key = get_api_key_by_platform(config_key)
            except ImportError:
                try:
                    # å°è¯•ä»æ–°çš„é…ç½®ç®¡ç†å™¨è·å–
                    from .settings_approach import get_qing_api_key_improved
                    final_api_key = get_qing_api_key_improved(config_key)
                except ImportError:
                    pass

        # ç­–ç•¥3: å›é€€åˆ°æ—§ç‰ˆAPIå¯†é’¥æœåŠ¡ï¼ˆä»…æ”¯æŒGLMï¼‰
        if not final_api_key and config_key in ["glm_api_key", "zhipuai_api_key"]:
            try:
                from .api_key_server import get_qing_api_key
                final_api_key = get_qing_api_key()
            except ImportError:
                pass

        # ç­–ç•¥4: ä»ä¸´æ—¶æ–‡ä»¶è·å–ï¼ˆå…¼å®¹æ€§ï¼‰
        if not final_api_key:
            try:
                import tempfile
                temp_file = Path(tempfile.gettempdir()) / f"qing_{config_key}_temp.txt"
                if temp_file.exists():
                    with open(temp_file, 'r', encoding='utf-8') as f:
                        temp_key = f.read().strip()
                        if temp_key:
                            final_api_key = temp_key
            except Exception:
                pass

        return final_api_key
    
    def generate_text(self, text_input: str, platform: str, model: str, max_tokens: int, history: int,
                     temperature: Optional[float] = 0.7, top_p: Optional[float] = 0.9, 
                     clear_history: Optional[bool] = False):
        """
        è°ƒç”¨Kimi APIç”Ÿæˆæ–‡æœ¬
        
        Args:
            text_input: è¾“å…¥æ–‡æœ¬
            platform: æœåŠ¡å¹³å°
            model: æ¨¡å‹åç§°
            max_tokens: æœ€å¤§tokenæ•°
            history: ä¿æŒçš„å†å²è½®æ•°
            temperature: æ¸©åº¦å‚æ•°
            top_p: top_på‚æ•°
            clear_history: æ˜¯å¦æ¸…é™¤å†å²
            
        Returns:
            tuple: (ç”Ÿæˆçš„æ–‡æœ¬, å¯¹è¯ä¿¡æ¯, tokenæ•°é‡)
        """
        try:
            # æ¸…é™¤å†å²è®°å½•
            if clear_history:
                self.conversation_history.clear()
            
            # è·å–å¹³å°é…ç½®
            platform_config = self.SERVICE_PLATFORMS.get(platform)
            if not platform_config:
                return (f"é”™è¯¯ï¼šä¸æ”¯æŒçš„å¹³å° '{platform}'", "é”™è¯¯çŠ¶æ€", 0)
            
            # éªŒè¯æ¨¡å‹æ˜¯å¦è¢«å½“å‰å¹³å°æ”¯æŒ
            supported_models = platform_config.get("models", [])
            if model not in supported_models:
                available_models = ", ".join(supported_models)
                platform_emoji = {"æœˆä¹‹æš—é¢": "ğŸŒ™", "ç«å±±å¼•æ“": "ğŸŒ‹", "é˜¿é‡Œäº‘ç™¾ç‚¼": "â˜ï¸", "ç¡…åŸºæµåŠ¨": "ğŸ’"}.get(platform, "ğŸ”¹")
                return (f"âŒ æ¨¡å‹å…¼å®¹æ€§é”™è¯¯\n\n{platform_emoji} å¹³å° '{platform}' ä¸æ”¯æŒæ¨¡å‹ '{model}'\n\nâœ… è¯¥å¹³å°æ”¯æŒçš„æ¨¡å‹ï¼š\n{available_models}\n\nğŸ’¡ æç¤ºï¼šè¯·é€‰æ‹©ä¸Šè¿°æ”¯æŒçš„æ¨¡å‹ä¹‹ä¸€ï¼Œæˆ–åˆ‡æ¢åˆ°æœˆä¹‹æš—é¢å¹³å°è·å¾—æ›´å¤šæ¨¡å‹é€‰æ‹©ã€‚", "æ¨¡å‹ä¸å…¼å®¹", 0)
            
            # è·å–APIå¯†é’¥
            api_key = self._get_api_key(platform_config)
            if not api_key:
                error_msg = f"""é”™è¯¯ï¼šæœªæä¾›{platform}çš„APIå¯†é’¥ã€‚è¯·å°è¯•ä»¥ä¸‹æ–¹æ³•ä¹‹ä¸€ï¼š

1. è®¾ç½®ç¯å¢ƒå˜é‡ï¼š{platform_config['api_key_env']}
2. åœ¨ğŸ¨QINGè®¾ç½®ä¸­é…ç½®APIå¯†é’¥
3. ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶è®¾ç½®å¯†é’¥

è¯·é…ç½®åé‡è¯•ã€‚"""
                return (error_msg, "APIå¯†é’¥ç¼ºå¤±", 0)
            
            # å¯¼å…¥openaiåº“
            try:
                from openai import OpenAI
            except ImportError:
                return ("é”™è¯¯ï¼šæœªå®‰è£…openaiåº“ã€‚è¯·è¿è¡Œï¼špip install openai", "ä¾èµ–ç¼ºå¤±", 0)
            
            # åˆå§‹åŒ–å®¢æˆ·ç«¯
            client = OpenAI(
                base_url=platform_config["base_url"],
                api_key=api_key
            )
            
            # è·å–å¯¹è¯å†å² - ä½¿ç”¨è‹±æ–‡å¹³å°é”®é¿å…ç¼–ç é—®é¢˜
            platform_key = platform_config.get("platform_key", platform)
            conversation_key = f"{platform_key}_{model}"
            if conversation_key not in self.conversation_history:
                self.conversation_history[conversation_key] = []
            
            current_history = self.conversation_history[conversation_key]
            
            # æ·»åŠ å½“å‰è¾“å…¥åˆ°å†å²
            current_history.append({"role": "user", "content": text_input})
            
            # é™åˆ¶å†å²é•¿åº¦
            if len(current_history) > history * 2:
                current_history = current_history[-(history * 2):]
                self.conversation_history[conversation_key] = current_history
            
            # æ ¹æ®å¹³å°è·å–å¯¹åº”çš„æ¨¡å‹åç§°
            platform_model_mapping = platform_config.get("model_mapping", {})
            api_model_name = platform_model_mapping.get(model, model.lower())
            
            # è°ƒç”¨API
            response = client.chat.completions.create(
                model=api_model_name,
                messages=current_history,
                max_tokens=max_tokens,
                temperature=temperature,
                top_p=top_p
            )
            
            # æå–å›å¤
            reply = response.choices[0].message.content
            
            # æ·»åŠ å›å¤åˆ°å†å²
            current_history.append({"role": "assistant", "content": reply})
            
            # è®¡ç®—tokenä½¿ç”¨æƒ…å†µ
            if hasattr(response, 'usage') and response.usage:
                total_tokens = response.usage.total_tokens
                prompt_tokens = getattr(response.usage, 'prompt_tokens', 0)
                completion_tokens = getattr(response.usage, 'completion_tokens', 0)
                token_count = total_tokens
            else:
                total_tokens = completion_tokens = prompt_tokens = token_count = 0
            
            # ç”Ÿæˆå¯¹è¯ä¿¡æ¯
            conversation_info = f"å¹³å°: {platform} | æ¨¡å‹: {model} | å†å²è½®æ•°: {len(current_history)//2} | æ€»Tokens: {total_tokens} (è¾“å…¥: {prompt_tokens}, è¾“å‡º: {completion_tokens}, é™åˆ¶: {max_tokens})"
            
            return (reply, conversation_info, total_tokens)
            
        except Exception as e:
            error_message = f"Kimi APIè°ƒç”¨å¤±è´¥ ({platform}): {str(e)}"
            return (error_message, "é”™è¯¯çŠ¶æ€", 0)

    @classmethod
    def IS_CHANGED(cls, **kwargs):
        # æ¯æ¬¡éƒ½é‡æ–°æ‰§è¡Œï¼Œå› ä¸ºæ˜¯APIè°ƒç”¨
        return float("nan")


# ComfyUIèŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "KimiLanguageAPI": KimiLanguageAPI
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "KimiLanguageAPI": "Kimi_è¯­è¨€ä¸¨API"
}
