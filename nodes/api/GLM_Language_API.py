# -*- coding: utf-8 -*-
"""
GLM Language APIèŠ‚ç‚¹
è°ƒç”¨æ™ºè°±GLMè¯­è¨€æ¨¡å‹APIè¿›è¡Œæ–‡æœ¬æ¨ç†
"""

import os
from typing import Optional, List, Dict, Any
from pathlib import Path

try:
    from zai import ZhipuAiClient
    ZAI_SDK_AVAILABLE = True
except ImportError:
    ZAI_SDK_AVAILABLE = False


class GLMLanguageAPI:
    """
    GLM Language APIèŠ‚ç‚¹
    
    åŠŸèƒ½ï¼š
    - è°ƒç”¨æ™ºè°±GLMæ¨¡å‹APIè¿›è¡Œæ–‡æœ¬æ¨ç†
    - æ”¯æŒå¤šç§GLMæ¨¡å‹é€‰æ‹©
    - æ”¯æŒå†å²å¯¹è¯ä¸Šä¸‹æ–‡
    - å¯è‡ªå®šä¹‰ç”Ÿæˆé•¿åº¦
    """
    
    # GLMæ¨¡å‹åˆ—è¡¨
    GLM_MODELS = [
        # GLM-4.5 ç³»åˆ—ï¼ˆæœ€æ–°ï¼‰
        "glm-4.5-flash",
        "glm-4.5",
        "glm-4.5-air",
        "glm-4.5-x",
        "glm-4.5-airx",
        
        # GLM-4 ç³»åˆ—
        "glm-4-flash",
        "glm-4-flash-250414",
        "GLM-4-FlashX",
        "GLM-4-PIus",
        "glm-4-0520", 
        "glm-4",
        "glm-4-air",
        "glm-4-airx",
        "glm-4-long",
        
        # GLM-3 ç³»åˆ—
        "glm-3-turbo"
    ]
    
    def __init__(self):
        self.conversation_history: List[Dict[str, str]] = []
        self.client: Optional[Any] = None  # ä½¿ç”¨Anyç±»å‹ä»¥æ”¯æŒä¸åŒçš„å®¢æˆ·ç«¯
        self._last_api_key: str = ""  # ç¼“å­˜APIå¯†é’¥ï¼Œé¿å…é‡å¤åˆå§‹åŒ–å®¢æˆ·ç«¯
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "text_input": ("STRING", {
                    "default": "ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ã€‚",
                    "multiline": True,
                    "tooltip": "è¾“å…¥è¦å‘é€ç»™GLMæ¨¡å‹çš„æ–‡æœ¬å†…å®¹"
                }),
                "model": (cls.GLM_MODELS, {
                    "default": "glm-4.5-flash",
                    "tooltip": "é€‰æ‹©è¦ä½¿ç”¨çš„GLMæ¨¡å‹"
                }),
                       "max_tokens": ("INT", {
                           "default": 3072,
                           "min": 1,
                           "max": 32768,
                           "step": 1,
                           "tooltip": "æ¨¡å‹ç”Ÿæˆæ–‡æœ¬æ—¶æœ€å¤šèƒ½ä½¿ç”¨çš„tokenæ•°é‡"
                       }),
                "history": ("INT", {
                    "default": 6,
                    "min": 1,
                    "max": 18,
                    "step": 1,
                    "tooltip": "ä¿æŒçš„å†å²å¯¹è¯è½®æ•°"
                }),
            },
            "optional": {
                "temperature": ("FLOAT", {
                    "default": 0.7,
                    "min": 0.0,
                    "max": 2.0,
                    "step": 0.1,
                    "tooltip": "æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§ï¼Œè¶Šé«˜è¶Šéšæœº"
                }),
                "top_p": ("FLOAT", {
                    "default": 0.9,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.1,
                    "tooltip": "æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„å¤šæ ·æ€§"
                }),
                "clear_history": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦æ¸…é™¤å†å²å¯¹è¯è®°å½•"
                }),
            }
        }
    
    RETURN_TYPES = ("STRING", "STRING", "INT")
    RETURN_NAMES = ("generated_text", "conversation_info", "token_count")
    FUNCTION = "generate_text"
    CATEGORY = "ğŸ¨QING/APIè°ƒç”¨"
    OUTPUT_NODE = False
    
    def generate_text(self, text_input: str, model: str, max_tokens: int, history: int,
                     temperature: float = 0.7, top_p: float = 0.9,
                     clear_history: bool = False) -> tuple:
        """
        ä½¿ç”¨GLMæ¨¡å‹ç”Ÿæˆæ–‡æœ¬
        
        å‚æ•°:
            text_input: è¾“å…¥æ–‡æœ¬
            model: æ¨¡å‹åç§°
            max_tokens: æœ€å¤§tokenæ•°
            history: å†å²å¯¹è¯è½®æ•°
            temperature: æ¸©åº¦å‚æ•°
            top_p: top_på‚æ•°
            clear_history: æ˜¯å¦æ¸…é™¤å†å²
            
        è¿”å›:
            tuple: (ç”Ÿæˆçš„æ–‡æœ¬, å¯¹è¯ä¿¡æ¯, tokenä½¿ç”¨é‡)
        """
        try:
            # æ£€æŸ¥ä¾èµ–
            if not ZAI_SDK_AVAILABLE:
                error_msg = "é”™è¯¯ï¼šæœªå®‰è£…zai-sdkåº“ã€‚è¯·è¿è¡Œï¼špip install zai-sdk"
                return (error_msg, "ä¾èµ–ç¼ºå¤±", 0)
            
            # å¦‚æœéœ€è¦æ¸…é™¤å†å²
            if clear_history:
                self.conversation_history.clear()
            
            # è·å–APIå¯†é’¥ï¼ˆå¤šé‡è·å–ç­–ç•¥ï¼‰
            final_api_key = ""
            
            # ç­–ç•¥1: ä»ğŸ¨QING APIå¯†é’¥æœåŠ¡å™¨è·å–
            try:
                from .api_key_server import get_qing_api_key
                final_api_key = get_qing_api_key()
            except ImportError:
                pass
            
            # ç­–ç•¥2: ä»JavaScriptå…¨å±€å˜é‡è·å–ï¼ˆé€šè¿‡ç‰¹æ®Šæ–¹å¼ï¼‰
            if not final_api_key:
                try:
                    # å°è¯•ä»å¯èƒ½çš„å…¨å±€çŠ¶æ€è·å–
                    import tempfile
                    temp_file = Path(tempfile.gettempdir()) / "qing_api_key_temp.txt"
                    if temp_file.exists():
                        with open(temp_file, 'r', encoding='utf-8') as f:
                            temp_key = f.read().strip()
                            if temp_key:
                                final_api_key = temp_key
                except Exception:
                    pass
            
            # ç­–ç•¥3: ä»ç¯å¢ƒå˜é‡è·å–
            if not final_api_key:
                final_api_key = os.getenv('ZHIPUAI_API_KEY', '')
            
            if not final_api_key:
                error_msg = """é”™è¯¯ï¼šæœªæä¾›APIå¯†é’¥ã€‚è¯·å°è¯•ä»¥ä¸‹æ–¹æ³•ä¹‹ä¸€ï¼š
1. åœ¨ğŸ¨QINGè®¾ç½®ä¸­é…ç½®æ™ºè°±GLM_API_Key
2. è®¾ç½®ç¯å¢ƒå˜é‡: set ZHIPUAI_API_KEY=your_key
3. ä¸´æ—¶æ–¹æ¡ˆï¼šåˆ›å»ºæ–‡ä»¶ %TEMP%\\qing_api_key_temp.txt å¹¶å†™å…¥æ‚¨çš„APIå¯†é’¥"""
                return (error_msg, "APIå¯†é’¥ç¼ºå¤±", 0)
            
            # åˆå§‹åŒ–å®¢æˆ·ç«¯ï¼ˆä½¿ç”¨æœ€æ–°çš„zai-sdkï¼‰
            if self.client is None or self._last_api_key != final_api_key:
                self.client = ZhipuAiClient(api_key=final_api_key)
                self._last_api_key = final_api_key
            
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = self._build_messages(text_input, history)
            
            # è°ƒç”¨API
            response = self.client.chat.completions.create(
                model=model,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature,
                top_p=top_p,
                stream=False
            )
            
            # æå–ç”Ÿæˆçš„æ–‡æœ¬
            if response.choices and len(response.choices) > 0:
                generated_text = response.choices[0].message.content
                
                # æ›´æ–°å¯¹è¯å†å²
                self._update_conversation_history(text_input, generated_text, history)
                
                # è·å–tokenä½¿ç”¨ä¿¡æ¯
                token_count = getattr(response.usage, 'total_tokens', 0) if hasattr(response, 'usage') else 0
                
                # ç”Ÿæˆå¯¹è¯ä¿¡æ¯
                conversation_info = self._generate_conversation_info(model, len(messages), token_count)
                
                return (generated_text, conversation_info, token_count)
            else:
                error_msg = "é”™è¯¯ï¼šAPIè¿”å›ç©ºå“åº”"
                return (error_msg, "APIå“åº”å¼‚å¸¸", 0)
                
        except ImportError as e:
            error_msg = f"å¯¼å…¥é”™è¯¯: {str(e)}"
            return (error_msg, "æ¨¡å—å¯¼å…¥å¤±è´¥", 0)
        except ConnectionError as e:
            error_msg = f"ç½‘ç»œè¿æ¥é”™è¯¯: {str(e)}"
            return (error_msg, "ç½‘ç»œå¼‚å¸¸", 0)
        except TimeoutError as e:
            error_msg = f"è¯·æ±‚è¶…æ—¶: {str(e)}"
            return (error_msg, "è¯·æ±‚è¶…æ—¶", 0)
        except ValueError as e:
            error_msg = f"å‚æ•°é”™è¯¯: {str(e)}"
            return (error_msg, "å‚æ•°å¼‚å¸¸", 0)
        except Exception as e:
            # å°è¯•è§£æå…·ä½“çš„APIé”™è¯¯
            error_detail = str(e)
            if "api_key" in error_detail.lower():
                error_msg = f"APIå¯†é’¥é”™è¯¯: {error_detail}"
                return (error_msg, "è®¤è¯å¤±è´¥", 0)
            elif "quota" in error_detail.lower() or "balance" in error_detail.lower():
                error_msg = f"ä½™é¢ä¸è¶³: {error_detail}"
                return (error_msg, "é…é¢ä¸è¶³", 0)
            elif "rate" in error_detail.lower():
                error_msg = f"è¯·æ±‚é¢‘ç‡è¿‡é«˜: {error_detail}"
                return (error_msg, "é¢‘ç‡é™åˆ¶", 0)
            else:
                error_msg = f"GLM APIè°ƒç”¨å¤±è´¥: {error_detail}"
                return (error_msg, f"é”™è¯¯: {type(e).__name__}", 0)
    
    def _build_messages(self, text_input: str, history: int) -> List[Dict[str, str]]:
        """æ„å»ºæ¶ˆæ¯åˆ—è¡¨"""
        messages = []
        
        # æ·»åŠ å†å²å¯¹è¯ï¼ˆé™åˆ¶æ•°é‡ï¼‰
        history_count = min(len(self.conversation_history), history * 2)  # æ¯è½®å¯¹è¯åŒ…å«ç”¨æˆ·å’ŒåŠ©æ‰‹æ¶ˆæ¯
        if history_count > 0:
            messages.extend(self.conversation_history[-history_count:])
        
        # æ·»åŠ å½“å‰ç”¨æˆ·è¾“å…¥
        messages.append({"role": "user", "content": text_input})
        
        return messages
    
    def _update_conversation_history(self, user_input: str, assistant_response: str, max_history: int):
        """æ›´æ–°å¯¹è¯å†å²"""
        # æ·»åŠ ç”¨æˆ·è¾“å…¥å’ŒåŠ©æ‰‹å›å¤
        self.conversation_history.append({"role": "user", "content": user_input})
        self.conversation_history.append({"role": "assistant", "content": assistant_response})
        
        # é™åˆ¶å†å²é•¿åº¦ï¼ˆæ¯è½®å¯¹è¯åŒ…å«ç”¨æˆ·å’ŒåŠ©æ‰‹æ¶ˆæ¯ï¼‰
        max_messages = max_history * 2
        if len(self.conversation_history) > max_messages:
            self.conversation_history = self.conversation_history[-max_messages:]
    
    def _generate_conversation_info(self, model: str, message_count: int, token_count: int) -> str:
        """ç”Ÿæˆå¯¹è¯ä¿¡æ¯"""
        history_rounds = len(self.conversation_history) // 2
        info_lines = [
            f"æ¨¡å‹: {model}",
            f"æœ¬æ¬¡æ¶ˆæ¯æ•°: {message_count}",
            f"å†å²è½®æ•°: {history_rounds}",
            f"Tokenä½¿ç”¨: {token_count}",
            f"å¯¹è¯çŠ¶æ€: æ­£å¸¸"
        ]
        return "\n".join(info_lines)
    
    @classmethod
    def IS_CHANGED(cls, **kwargs):
        # æ¯æ¬¡éƒ½é‡æ–°æ‰§è¡Œï¼Œå› ä¸ºæ˜¯APIè°ƒç”¨
        return float("nan")


# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "GLMLanguageAPI": GLMLanguageAPI
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "GLMLanguageAPI": "GLM_è¯­è¨€ä¸¨API"
}
