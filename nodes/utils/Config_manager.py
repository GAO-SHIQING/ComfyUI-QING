# -*- coding: utf-8 -*-
"""
é…ç½®æ–‡ä»¶ç®¡ç†èŠ‚ç‚¹
åŠŸèƒ½ï¼šå¯¼å‡ºå’Œå¯¼å…¥ComfyUIçš„é…ç½®ä¿¡æ¯ã€å·¥ä½œæµã€è¾“å…¥è¾“å‡ºæ–‡ä»¶ç­‰
"""

import os
import json
import shutil
import zipfile
from datetime import datetime
from pathlib import Path


class ConfigExport:
    """
    é…ç½®æ–‡ä»¶å¯¼å‡ºèŠ‚ç‚¹
    åŠŸèƒ½ï¼šå¯¼å‡ºComfyUIçš„å„ç±»é…ç½®æ–‡ä»¶å’Œèµ„æº
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "export_node_info": ("BOOLEAN", {
                    "default": True,
                    "label_on": "å¼€å¯",
                    "label_off": "å…³é—­",
                    "tooltip": "å¯¼å‡ºèŠ‚ç‚¹ä¿¡æ¯ï¼ˆcustom_nodesåˆ—è¡¨å’Œé…ç½®ï¼‰"
                }),
                "export_frontend_settings": ("BOOLEAN", {
                    "default": True,
                    "label_on": "å¼€å¯",
                    "label_off": "å…³é—­",
                    "tooltip": "å¯¼å‡ºå‰ç«¯è®¾ç½®ï¼ˆç•Œé¢é…ç½®ã€ç”¨æˆ·åå¥½ï¼‰"
                }),
                "export_dependencies": ("BOOLEAN", {
                    "default": True,
                    "label_on": "å¼€å¯",
                    "label_off": "å…³é—­",
                    "tooltip": "å¯¼å‡ºç¯å¢ƒä¾èµ–ï¼ˆrequirements.txtã€å·²å®‰è£…åŒ…åˆ—è¡¨ï¼‰"
                }),
                "export_workflows": ("BOOLEAN", {
                    "default": False,
                    "label_on": "å¼€å¯",
                    "label_off": "å…³é—­",
                    "tooltip": "å¯¼å‡ºå·¥ä½œæµæ–‡ä»¶ï¼ˆworkflowç›®å½•ï¼‰"
                }),
                "export_inputs": ("BOOLEAN", {
                    "default": False,
                    "label_on": "å¼€å¯",
                    "label_off": "å…³é—­",
                    "tooltip": "å¯¼å‡ºè¾“å…¥æ–‡ä»¶ï¼ˆinputç›®å½•ï¼Œå¯èƒ½è¾ƒå¤§ï¼‰"
                }),
                "export_outputs": ("BOOLEAN", {
                    "default": False,
                    "label_on": "å¼€å¯",
                    "label_off": "å…³é—­",
                    "tooltip": "å¯¼å‡ºè¾“å‡ºæ–‡ä»¶ï¼ˆoutputç›®å½•ï¼Œå¯èƒ½è¾ƒå¤§ï¼‰"
                }),
                "output_path": ("STRING", {
                    "default": "",
                    "multiline": False,
                    "tooltip": "è‡ªå®šä¹‰ä¿å­˜è·¯å¾„ï¼ˆç»å¯¹è·¯å¾„ï¼‰ï¼Œç•™ç©ºåˆ™ä¿å­˜åˆ°é»˜è®¤è·¯å¾„"
                }),
            },
        }

    CATEGORY = "ğŸ¨QING/é…ç½®ç®¡ç†"
    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("result_analysis",)
    FUNCTION = "export_config"
    OUTPUT_NODE = True

    def export_config(self, export_node_info, export_frontend_settings, export_dependencies,
                     export_workflows, export_inputs, export_outputs, output_path):
        """
        ä¸»å¤„ç†å‡½æ•°ï¼šå¯¼å‡ºComfyUIé…ç½®
        
        å‚æ•°:
            export_node_info: æ˜¯å¦å¯¼å‡ºèŠ‚ç‚¹ä¿¡æ¯
            export_frontend_settings: æ˜¯å¦å¯¼å‡ºå‰ç«¯è®¾ç½®
            export_dependencies: æ˜¯å¦å¯¼å‡ºç¯å¢ƒä¾èµ–
            export_workflows: æ˜¯å¦å¯¼å‡ºå·¥ä½œæµ
            export_inputs: æ˜¯å¦å¯¼å‡ºè¾“å…¥æ–‡ä»¶
            export_outputs: æ˜¯å¦å¯¼å‡ºè¾“å‡ºæ–‡ä»¶
            output_path: è‡ªå®šä¹‰è¾“å‡ºè·¯å¾„
            
        è¿”å›:
            tuple: (ç»“æœåˆ†ææ–‡æœ¬,)
        """
        try:
            # è·å–ComfyUIæ ¹ç›®å½•
            comfyui_root = self._get_comfyui_root()
            
            # ç¡®å®šè¾“å‡ºè·¯å¾„
            if output_path and output_path.strip():
                export_dir = Path(output_path.strip())
                # éªŒè¯è‡ªå®šä¹‰è·¯å¾„
                if not export_dir.is_absolute():
                    return ("âŒ é”™è¯¯ï¼šè¾“å‡ºè·¯å¾„å¿…é¡»æ˜¯ç»å¯¹è·¯å¾„\nå½“å‰è·¯å¾„ï¼š" + str(export_dir),)
            else:
                # é»˜è®¤è·¯å¾„ï¼šComfyUIæ ¹ç›®å½•/output/config_backups
                export_dir = comfyui_root / "output" / "config_backups"
            
            # åˆ›å»ºå¯¼å‡ºç›®å½•
            try:
                export_dir.mkdir(parents=True, exist_ok=True)
            except PermissionError:
                return (f"âŒ é”™è¯¯ï¼šæ— æƒé™è®¿é—®è¾“å‡ºè·¯å¾„\nè·¯å¾„ï¼š{export_dir}",)
            except Exception as e:
                return (f"âŒ é”™è¯¯ï¼šæ— æ³•åˆ›å»ºè¾“å‡ºç›®å½•\nè·¯å¾„ï¼š{export_dir}\né”™è¯¯ï¼š{str(e)}",)
            
            # åˆ›å»ºæ—¶é—´æˆ³æ–‡ä»¶åï¼ˆé¿å…é‡å¤ï¼‰
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            zip_filename = f"comfyui_config_{timestamp}.zip"
            zip_path = export_dir / zip_filename
            
            # å¤„ç†æ–‡ä»¶åå†²çªï¼ˆæå°‘æƒ…å†µï¼‰
            counter = 1
            while zip_path.exists():
                zip_filename = f"comfyui_config_{timestamp}_{counter}.zip"
                zip_path = export_dir / zip_filename
                counter += 1
            
            # å¯¼å‡ºç»Ÿè®¡
            stats = {
                "exported_items": [],
                "skipped_items": [],
                "file_count": 0,
                "total_size": 0,
                "errors": []
            }
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºç»„ç»‡æ–‡ä»¶ï¼ˆç¡®ä¿å”¯ä¸€æ€§ï¼‰
            temp_counter = 0
            temp_dir = export_dir / f"temp_{timestamp}"
            while temp_dir.exists():
                temp_counter += 1
                temp_dir = export_dir / f"temp_{timestamp}_{temp_counter}"
            temp_dir.mkdir(exist_ok=True)
            
            try:
                # å¯¼å‡ºå„ç±»é…ç½®
                if export_node_info:
                    self._export_node_info(comfyui_root, temp_dir, stats)
                
                if export_frontend_settings:
                    self._export_frontend_settings(comfyui_root, temp_dir, stats)
                
                if export_dependencies:
                    self._export_dependencies(comfyui_root, temp_dir, stats)
                
                if export_workflows:
                    self._export_workflows(comfyui_root, temp_dir, stats)
                
                if export_inputs:
                    self._export_inputs(comfyui_root, temp_dir, stats)
                
                if export_outputs:
                    self._export_outputs(comfyui_root, temp_dir, stats)
                
                # æ‰“åŒ…æˆzipæ–‡ä»¶
                if stats["file_count"] > 0:
                    # åˆ›å»ºå¯¼å‡ºå…ƒæ•°æ®
                    self._create_export_metadata(temp_dir, timestamp, stats,
                                                export_node_info, export_frontend_settings,
                                                export_dependencies, export_workflows,
                                                export_inputs, export_outputs)
                    
                    self._create_zip(temp_dir, zip_path, stats)
                    result = self._generate_success_report(zip_path, stats, timestamp)
                else:
                    result = "âš ï¸ æœªé€‰æ‹©ä»»ä½•å¯¼å‡ºé¡¹ï¼Œæœªç”Ÿæˆå¯¼å‡ºæ–‡ä»¶"
                
            finally:
                # æ¸…ç†ä¸´æ—¶ç›®å½•
                if temp_dir.exists():
                    shutil.rmtree(temp_dir, ignore_errors=True)
            
            return (result,)
            
        except Exception as e:
            error_msg = f"âŒ å¯¼å‡ºå¤±è´¥\n\né”™è¯¯ä¿¡æ¯ï¼š{str(e)}\n\nè¯·æ£€æŸ¥è·¯å¾„æƒé™å’Œç£ç›˜ç©ºé—´"
            return (error_msg,)
    
    def _get_comfyui_root(self):
        """è·å–ComfyUIæ ¹ç›®å½•"""
        try:
            import folder_paths
            # å°è¯•ä»folder_pathsè·å–åŸºç¡€è·¯å¾„
            base_path = folder_paths.base_path
            return Path(base_path)
        except:
            # å›é€€ï¼šä»å½“å‰æ–‡ä»¶å‘ä¸ŠæŸ¥æ‰¾
            current = Path(__file__).resolve()
            while current.parent != current:
                if (current / "main.py").exists() or (current / "comfyui").exists():
                    return current
                current = current.parent
            # æœ€åå›é€€
            return Path.cwd()
    
    def _get_github_url(self, node_path):
        """è·å–èŠ‚ç‚¹çš„GitHubåœ°å€"""
        try:
            git_config = node_path / ".git" / "config"
            if not git_config.exists():
                return ""
            
            # è¯»å–git configæ–‡ä»¶
            with open(git_config, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æŸ¥æ‰¾remote "origin"çš„url
            import re
            # åŒ¹é… url = xxx æ ¼å¼
            url_match = re.search(r'url\s*=\s*(.+)', content)
            if url_match:
                url = url_match.group(1).strip()
                
                # è½¬æ¢SSHæ ¼å¼åˆ°HTTPSæ ¼å¼
                # git@github.com:user/repo.git -> https://github.com/user/repo
                if url.startswith('git@github.com:'):
                    url = url.replace('git@github.com:', 'https://github.com/')
                
                # ç§»é™¤.gitåç¼€
                if url.endswith('.git'):
                    url = url[:-4]
                
                return url
            
            return ""
            
        except Exception as e:
            # å¦‚æœè·å–å¤±è´¥ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²è€Œä¸æ˜¯å¼•å‘é”™è¯¯
            return ""
    
    def _create_export_metadata(self, temp_dir, timestamp, stats, 
                                export_node_info, export_frontend_settings,
                                export_dependencies, export_workflows,
                                export_inputs, export_outputs):
        """åˆ›å»ºå¯¼å‡ºå…ƒæ•°æ®æ–‡ä»¶"""
        try:
            import sys
            import platform
            
            metadata = {
                "export_info": {
                    "timestamp": timestamp,
                    "datetime": datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    "exporter": "ComfyUI-QING Config Manager",
                    "version": "1.0.0"
                },
                "export_options": {
                    "node_info": export_node_info,
                    "frontend_settings": export_frontend_settings,
                    "dependencies": export_dependencies,
                    "workflows": export_workflows,
                    "inputs": export_inputs,
                    "outputs": export_outputs
                },
                "statistics": {
                    "total_files": stats["file_count"],
                    "exported_items": stats["exported_items"],
                    "errors": stats["errors"]
                },
                "system_info": {
                    "python_version": sys.version,
                    "platform": platform.platform(),
                    "os": platform.system(),
                    "architecture": platform.machine()
                }
            }
            
            metadata_file = temp_dir / "export_metadata.json"
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            
            stats["file_count"] += 1
            
        except Exception as e:
            stats["errors"].append(f"åˆ›å»ºå…ƒæ•°æ®å¤±è´¥: {str(e)}")
    
    def _export_node_info(self, root, temp_dir, stats):
        """å¯¼å‡ºèŠ‚ç‚¹ä¿¡æ¯"""
        try:
            node_info_dir = temp_dir / "node_info"
            node_info_dir.mkdir(exist_ok=True)
            
            # å¯¼å‡ºcustom_nodesç›®å½•åˆ—è¡¨
            custom_nodes_dir = root / "custom_nodes"
            if custom_nodes_dir.exists():
                nodes_list = []
                for item in custom_nodes_dir.iterdir():
                    if item.is_dir() and not item.name.startswith('.'):
                        node_data = {
                            "name": item.name,
                            "path": str(item.relative_to(root)),
                            "github_url": self._get_github_url(item),
                            "has_init": (item / "__init__.py").exists(),
                            "has_requirements": (item / "requirements.txt").exists(),
                            "has_pyproject": (item / "pyproject.toml").exists(),
                            "has_readme": any((item / f"README{ext}").exists() for ext in [".md", ".MD", ".txt", ""]),
                            "has_license": any((item / f"LICENSE{ext}").exists() for ext in ["", ".txt", ".md"]),
                        }
                        
                        # å°è¯•è·å–pyproject.tomlä¸­çš„ç‰ˆæœ¬ä¿¡æ¯
                        pyproject_file = item / "pyproject.toml"
                        if pyproject_file.exists():
                            try:
                                with open(pyproject_file, 'r', encoding='utf-8') as f:
                                    content = f.read()
                                    # ç®€å•æå–versionå­—æ®µ
                                    import re
                                    version_match = re.search(r'version\s*=\s*["\']([^"\']+)["\']', content)
                                    if version_match:
                                        node_data["version"] = version_match.group(1)
                            except:
                                pass
                        
                        nodes_list.append(node_data)
                
                # ä¿å­˜èŠ‚ç‚¹åˆ—è¡¨
                nodes_file = node_info_dir / "custom_nodes_list.json"
                with open(nodes_file, 'w', encoding='utf-8') as f:
                    json.dump(nodes_list, f, indent=2, ensure_ascii=False)
                
                stats["exported_items"].append(f"èŠ‚ç‚¹ä¿¡æ¯ ({len(nodes_list)}ä¸ªèŠ‚ç‚¹)")
                stats["file_count"] += 1
            
        except Exception as e:
            stats["errors"].append(f"å¯¼å‡ºèŠ‚ç‚¹ä¿¡æ¯å¤±è´¥: {str(e)}")
    
    def _export_frontend_settings(self, root, temp_dir, stats):
        """å¯¼å‡ºå‰ç«¯è®¾ç½®"""
        try:
            settings_dir = temp_dir / "frontend_settings"
            settings_dir.mkdir(exist_ok=True)
            
            # å¯èƒ½çš„è®¾ç½®æ–‡ä»¶ä½ç½®
            setting_paths = [
                root / "user" / "default" / "comfy.settings.json",
                root / "user" / "comfy.settings.json",
                root / "web" / "user.settings.json",
            ]
            
            exported_count = 0
            for setting_path in setting_paths:
                if setting_path.exists():
                    dest = settings_dir / setting_path.name
                    shutil.copy2(setting_path, dest)
                    exported_count += 1
            
            if exported_count > 0:
                stats["exported_items"].append("å‰ç«¯è®¾ç½®")
                stats["file_count"] += exported_count
            
        except Exception as e:
            stats["errors"].append(f"å¯¼å‡ºå‰ç«¯è®¾ç½®å¤±è´¥: {str(e)}")
    
    def _export_dependencies(self, root, temp_dir, stats):
        """å¯¼å‡ºç¯å¢ƒä¾èµ–ï¼ˆæ•´ä¸ªPythonç¯å¢ƒçš„æ‰€æœ‰ä¾èµ–ï¼‰"""
        try:
            deps_dir = temp_dir / "dependencies"
            deps_dir.mkdir(exist_ok=True)
            
            # è·å–Pythonç‰ˆæœ¬ä¿¡æ¯
            import sys
            import platform
            
            # å¯¼å‡ºç¯å¢ƒä¿¡æ¯
            env_info_file = deps_dir / "environment_info.txt"
            with open(env_info_file, 'w', encoding='utf-8') as f:
                f.write("# Pythonç¯å¢ƒä¿¡æ¯\n")
                f.write(f"# å¯¼å‡ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                f.write(f"Pythonç‰ˆæœ¬: {sys.version}\n")
                f.write(f"Pythonè·¯å¾„: {sys.executable}\n")
                f.write(f"æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}\n")
                f.write(f"å¹³å°: {platform.platform()}\n")
                f.write(f"æ¶æ„: {platform.machine()}\n\n")
            
            stats["file_count"] += 1
            
            # å¯¼å‡ºpip freezeç»“æœï¼ˆæ•´ä¸ªPythonç¯å¢ƒçš„æ‰€æœ‰å·²å®‰è£…åŒ…ï¼‰
            pip_success = False
            try:
                import subprocess
                
                # å°è¯•å¤šç§pipè°ƒç”¨æ–¹å¼
                pip_commands = [
                    ['pip', 'freeze'],
                    [sys.executable, '-m', 'pip', 'freeze'],  # python -m pip freeze
                    ['pip3', 'freeze'],
                ]
                
                for cmd in pip_commands:
                    try:
                        result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
                        if result.returncode == 0 and result.stdout.strip():
                            freeze_file = deps_dir / "python_packages.txt"
                            with open(freeze_file, 'w', encoding='utf-8') as f:
                                f.write("# Pythonç¯å¢ƒå®Œæ•´åŒ…åˆ—è¡¨\n")
                                f.write(f"# å¯¼å‡ºæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                                f.write(f"# Pythonç‰ˆæœ¬: {sys.version.split()[0]}\n")
                                f.write(f"# ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å®‰è£…: pip install -r python_packages.txt\n\n")
                                f.write(result.stdout)
                            
                            # ç»Ÿè®¡åŒ…æ•°é‡
                            package_count = len([line for line in result.stdout.split('\n') if line.strip() and not line.startswith('#')])
                            
                            stats["exported_items"].append(f"ç¯å¢ƒä¾èµ– ({package_count}ä¸ªåŒ…)")
                            stats["file_count"] += 1
                            pip_success = True
                            break
                    except (FileNotFoundError, subprocess.TimeoutExpired):
                        continue
                
                if not pip_success:
                    stats["errors"].append("pipå‘½ä»¤æœªæ‰¾åˆ°æˆ–æ‰§è¡Œå¤±è´¥ï¼ˆå·²å°è¯•å¤šç§è°ƒç”¨æ–¹å¼ï¼‰ï¼Œç¯å¢ƒä¿¡æ¯ä»å·²å¯¼å‡º")
                    
            except subprocess.TimeoutExpired:
                stats["errors"].append("pip freezeæ‰§è¡Œè¶…æ—¶ï¼ˆ30ç§’ï¼‰ï¼Œç¯å¢ƒä¿¡æ¯ä»å·²å¯¼å‡º")
            except Exception as e:
                stats["errors"].append(f"è·å–åŒ…åˆ—è¡¨å¤±è´¥: {str(e)}ï¼Œç¯å¢ƒä¿¡æ¯ä»å·²å¯¼å‡º")
            
        except Exception as e:
            stats["errors"].append(f"å¯¼å‡ºç¯å¢ƒä¾èµ–å¤±è´¥: {str(e)}")
    
    def _export_workflows(self, root, temp_dir, stats):
        """å¯¼å‡ºå·¥ä½œæµæ–‡ä»¶"""
        try:
            workflow_sources = [
                root / "user" / "default" / "workflows",
                root / "workflows",
                root / "my_workflows",
            ]
            
            workflow_dir = temp_dir / "workflows"
            workflow_dir.mkdir(exist_ok=True)
            
            total_files = 0
            for source in workflow_sources:
                if source.exists() and source.is_dir():
                    for file in source.rglob("*.json"):
                        rel_path = file.relative_to(source)
                        dest = workflow_dir / source.name / rel_path
                        dest.parent.mkdir(parents=True, exist_ok=True)
                        shutil.copy2(file, dest)
                        total_files += 1
            
            if total_files > 0:
                stats["exported_items"].append(f"å·¥ä½œæµæ–‡ä»¶ ({total_files}ä¸ª)")
                stats["file_count"] += total_files
            
        except Exception as e:
            stats["errors"].append(f"å¯¼å‡ºå·¥ä½œæµå¤±è´¥: {str(e)}")
    
    def _export_inputs(self, root, temp_dir, stats):
        """å¯¼å‡ºè¾“å…¥æ–‡ä»¶"""
        try:
            input_dir = root / "input"
            if input_dir.exists() and input_dir.is_dir():
                dest_dir = temp_dir / "input"
                shutil.copytree(input_dir, dest_dir, dirs_exist_ok=True)
                
                # ç»Ÿè®¡æ–‡ä»¶æ•°é‡
                file_count = sum(1 for _ in dest_dir.rglob("*") if _.is_file())
                stats["exported_items"].append(f"è¾“å…¥æ–‡ä»¶ ({file_count}ä¸ª)")
                stats["file_count"] += file_count
            
        except Exception as e:
            stats["errors"].append(f"å¯¼å‡ºè¾“å…¥æ–‡ä»¶å¤±è´¥: {str(e)}")
    
    def _export_outputs(self, root, temp_dir, stats):
        """å¯¼å‡ºè¾“å‡ºæ–‡ä»¶ï¼ˆæ’é™¤å¤‡ä»½å’Œä¸´æ—¶æ–‡ä»¶ï¼‰"""
        try:
            output_dir = root / "output"
            if output_dir.exists() and output_dir.is_dir():
                dest_dir = temp_dir / "output"
                dest_dir.mkdir(exist_ok=True)
                
                file_count = 0
                for item in output_dir.iterdir():
                    # è·³è¿‡å¤‡ä»½ç›®å½•å’Œä¸´æ—¶ç›®å½•
                    if item.name == "config_backups" or item.name.startswith("temp_import_"):
                        continue
                    
                    dest = dest_dir / item.name
                    if item.is_dir():
                        shutil.copytree(item, dest, dirs_exist_ok=True)
                        file_count += sum(1 for _ in dest.rglob("*") if _.is_file())
                    else:
                        shutil.copy2(item, dest)
                        file_count += 1
                
                if file_count > 0:
                    stats["exported_items"].append(f"è¾“å‡ºæ–‡ä»¶ ({file_count}ä¸ª)")
                    stats["file_count"] += file_count
            
        except Exception as e:
            stats["errors"].append(f"å¯¼å‡ºè¾“å‡ºæ–‡ä»¶å¤±è´¥: {str(e)}")
    
    def _create_zip(self, source_dir, zip_path, stats):
        """åˆ›å»ºZIPå‹ç¼©åŒ…"""
        try:
            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for file in source_dir.rglob("*"):
                    if file.is_file():
                        arcname = file.relative_to(source_dir)
                        zipf.write(file, arcname)
                        stats["total_size"] += file.stat().st_size
        except Exception as e:
            stats["errors"].append(f"åˆ›å»ºå‹ç¼©åŒ…å¤±è´¥: {str(e)}")
            raise
    
    def _generate_success_report(self, zip_path, stats, timestamp):
        """ç”ŸæˆæˆåŠŸæŠ¥å‘Š"""
        size_mb = stats["total_size"] / (1024 * 1024)
        
        report = "âœ… é…ç½®å¯¼å‡ºæˆåŠŸï¼\n\n"
        report += f"ğŸ“¦ å¯¼å‡ºæ–‡ä»¶ï¼š{zip_path.name}\n"
        report += f"ğŸ“‚ ä¿å­˜è·¯å¾„ï¼š{zip_path.parent}\n"
        report += f"ğŸ“Š æ–‡ä»¶æ•°é‡ï¼š{stats['file_count']} ä¸ª\n"
        report += f"ğŸ’¾ å‹ç¼©å¤§å°ï¼š{size_mb:.2f} MB\n"
        report += f"ğŸ• å¯¼å‡ºæ—¶é—´ï¼š{timestamp}\n\n"
        
        if stats["exported_items"]:
            report += "ğŸ“‹ å·²å¯¼å‡ºå†…å®¹ï¼š\n"
            for item in stats["exported_items"]:
                report += f"  âœ“ {item}\n"
        
        if stats["errors"]:
            report += "\nâš ï¸ éƒ¨åˆ†å†…å®¹å¯¼å‡ºå¤±è´¥ï¼š\n"
            for error in stats["errors"]:
                report += f"  âœ— {error}\n"
        
        return report


class ConfigImport:
    """
    é…ç½®æ–‡ä»¶å¯¼å…¥èŠ‚ç‚¹
    åŠŸèƒ½ï¼šå¯¼å…¥ComfyUIçš„å„ç±»é…ç½®æ–‡ä»¶å’Œèµ„æº
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "import_path": ("STRING", {
                    "default": "",
                    "multiline": False,
                    "tooltip": "å¯¼å…¥è·¯å¾„ï¼ˆæ”¯æŒZIPå‹ç¼©åŒ…æˆ–æ–‡ä»¶å¤¹çš„ç»å¯¹è·¯å¾„ï¼‰"
                }),
                "import_mode": (["overwrite", "skip", "auto_rename"], {
                    "default": "overwrite",
                    "tooltip": "å¯¼å…¥å½¢å¼ï¼šoverwrite(è¦†ç›–å·²å­˜åœ¨æ–‡ä»¶) skip(è·³è¿‡å·²å­˜åœ¨æ–‡ä»¶) auto_rename(è‡ªåŠ¨é‡å‘½å)"
                }),
                "create_backup": ("BOOLEAN", {
                    "default": True,
                    "label_on": "å¼€å¯",
                    "label_off": "å…³é—­",
                    "tooltip": "å¯¼å…¥å‰åˆ›å»ºç°æœ‰é…ç½®çš„å¤‡ä»½ï¼ˆä¿å­˜åˆ°outputç›®å½•ï¼‰"
                }),
            },
        }

    CATEGORY = "ğŸ¨QING/é…ç½®ç®¡ç†"
    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("result_analysis",)
    FUNCTION = "import_config"
    OUTPUT_NODE = True

    def import_config(self, import_path, import_mode="auto_rename", create_backup=True):
        """
        ä¸»å¤„ç†å‡½æ•°ï¼šå¯¼å…¥ComfyUIé…ç½®
        
        å‚æ•°:
            import_path: å¯¼å…¥æ–‡ä»¶è·¯å¾„ï¼ˆæ”¯æŒZIPæ–‡ä»¶æˆ–æ–‡ä»¶å¤¹ï¼‰
            import_mode: å¯¼å…¥æ¨¡å¼ï¼ˆoverwrite/skip/auto_renameï¼‰
            create_backup: æ˜¯å¦åˆ›å»ºå¤‡ä»½
            
        è¿”å›:
            tuple: (ç»“æœåˆ†ææ–‡æœ¬,)
        """
        try:
            # éªŒè¯å¯¼å…¥è·¯å¾„
            if not import_path or not import_path.strip():
                return ("âŒ é”™è¯¯ï¼šæœªæŒ‡å®šå¯¼å…¥è·¯å¾„",)
            
            source_path = Path(import_path.strip())
            if not source_path.exists():
                return (f"âŒ é”™è¯¯ï¼šè·¯å¾„ä¸å­˜åœ¨\nè·¯å¾„ï¼š{source_path}",)
            
            # è·å–ComfyUIæ ¹ç›®å½•
            comfyui_root = self._get_comfyui_root()
            
            # å¯¼å…¥ç»Ÿè®¡
            stats = {
                "imported_items": [],
                "skipped_items": [],
                "renamed_items": [],
                "file_count": 0,
                "backup_created": False,
                "errors": [],
                "import_type": ""
            }
            
            # åˆ›å»ºä¸´æ—¶è§£å‹ç›®å½•
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            temp_dir = comfyui_root / f"temp_import_{timestamp}"
            temp_dir.mkdir(exist_ok=True)
            
            try:
                # åˆ¤æ–­æ˜¯ZIPæ–‡ä»¶è¿˜æ˜¯æ–‡ä»¶å¤¹
                if source_path.is_file():
                    if source_path.suffix.lower() == '.zip':
                        # ZIPæ–‡ä»¶ï¼šéªŒè¯å®Œæ•´æ€§å¹¶è§£å‹
                        stats["import_type"] = "ZIPå‹ç¼©åŒ…"
                        try:
                            with zipfile.ZipFile(source_path, 'r') as zipf:
                                # æµ‹è¯•ZIPæ–‡ä»¶å®Œæ•´æ€§
                                bad_file = zipf.testzip()
                                if bad_file:
                                    return (f"âŒ é”™è¯¯ï¼šZIPæ–‡ä»¶å·²æŸå\næŸåçš„æ–‡ä»¶ï¼š{bad_file}",)
                                # è§£å‹åˆ°ä¸´æ—¶ç›®å½•
                                zipf.extractall(temp_dir)
                        except zipfile.BadZipFile:
                            return (f"âŒ é”™è¯¯ï¼šä¸æ˜¯æœ‰æ•ˆçš„ZIPæ–‡ä»¶\næ–‡ä»¶ï¼š{source_path.name}",)
                        except Exception as e:
                            return (f"âŒ é”™è¯¯ï¼šZIPæ–‡ä»¶è§£å‹å¤±è´¥\né”™è¯¯ï¼š{str(e)}",)
                    else:
                        return (f"âŒ é”™è¯¯ï¼šä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼\næ”¯æŒï¼šZIPå‹ç¼©åŒ…æˆ–æ–‡ä»¶å¤¹\nå½“å‰ï¼š{source_path.suffix}",)
                elif source_path.is_dir():
                    # æ–‡ä»¶å¤¹ï¼šç›´æ¥å¤åˆ¶åˆ°ä¸´æ—¶ç›®å½•
                    stats["import_type"] = "æ–‡ä»¶å¤¹"
                    shutil.copytree(source_path, temp_dir, dirs_exist_ok=True)
                else:
                    return (f"âŒ é”™è¯¯ï¼šä¸æ”¯æŒçš„è·¯å¾„ç±»å‹\nè·¯å¾„ï¼š{source_path}",)
                
                # åˆ›å»ºå¤‡ä»½ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if create_backup:
                    self._create_backup(comfyui_root, stats)
                
                # å¯¼å…¥å„ç±»é…ç½®
                self._import_node_info(temp_dir, comfyui_root, import_mode, stats)
                self._import_frontend_settings(temp_dir, comfyui_root, import_mode, stats)
                self._import_dependencies(temp_dir, comfyui_root, import_mode, stats)
                self._import_workflows(temp_dir, comfyui_root, import_mode, stats)
                self._import_inputs(temp_dir, comfyui_root, import_mode, stats)
                self._import_outputs(temp_dir, comfyui_root, import_mode, stats)
                
                result = self._generate_import_success_report(source_path, stats, import_mode)
                
            finally:
                # æ¸…ç†ä¸´æ—¶ç›®å½•
                if temp_dir.exists():
                    shutil.rmtree(temp_dir, ignore_errors=True)
            
            return (result,)
            
        except Exception as e:
            error_msg = f"âŒ å¯¼å…¥å¤±è´¥\n\né”™è¯¯ä¿¡æ¯ï¼š{str(e)}\n\nè¯·æ£€æŸ¥è·¯å¾„æ ¼å¼å’Œæƒé™"
            return (error_msg,)
    
    def _get_comfyui_root(self):
        """è·å–ComfyUIæ ¹ç›®å½•"""
        try:
            import folder_paths
            base_path = folder_paths.base_path
            return Path(base_path)
        except:
            current = Path(__file__).resolve()
            while current.parent != current:
                if (current / "main.py").exists() or (current / "comfyui").exists():
                    return current
                current = current.parent
            return Path.cwd()
    
    def _create_backup(self, root, stats):
        """åˆ›å»ºç°æœ‰é…ç½®çš„å¤‡ä»½ï¼ˆä¿å­˜åˆ°outputç›®å½•ï¼‰"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # ä½¿ç”¨outputç›®å½•ä½œä¸ºå¤‡ä»½ç›®å½•
            try:
                import folder_paths
                output_dir = Path(folder_paths.get_output_directory())
            except:
                output_dir = root / "output"
            
            backup_dir = output_dir / "config_backups" / f"before_import_{timestamp}"
            backup_dir.mkdir(parents=True, exist_ok=True)
            
            # å¤‡ä»½å…³é”®é…ç½®ç›®å½•
            backup_targets = [
                (root / "user", "user"),
                (root / "workflows", "workflows"),
            ]
            
            backup_count = 0
            for source, name in backup_targets:
                if source.exists():
                    dest = backup_dir / name
                    if source.is_dir():
                        shutil.copytree(source, dest, dirs_exist_ok=True)
                        backup_count += 1
                    else:
                        shutil.copy2(source, dest)
                        backup_count += 1
            
            if backup_count > 0:
                stats["backup_created"] = True
                stats["backup_path"] = str(backup_dir)
            else:
                stats["errors"].append("æœªæ‰¾åˆ°éœ€è¦å¤‡ä»½çš„é…ç½®ç›®å½•")
            
        except Exception as e:
            stats["errors"].append(f"åˆ›å»ºå¤‡ä»½å¤±è´¥: {str(e)}")
    
    def _copy_file_with_mode(self, source, dest, mode, stats):
        """æ ¹æ®æ¨¡å¼å¤åˆ¶æ–‡ä»¶"""
        try:
            if not source.exists():
                return False
            
            dest.parent.mkdir(parents=True, exist_ok=True)
            
            if not dest.exists():
                # ç›®æ ‡ä¸å­˜åœ¨ï¼Œç›´æ¥å¤åˆ¶
                shutil.copy2(source, dest)
                return True
            else:
                # ç›®æ ‡å·²å­˜åœ¨ï¼Œæ ¹æ®æ¨¡å¼å¤„ç†
                if mode == "overwrite":
                    shutil.copy2(source, dest)
                    return True
                elif mode == "skip":
                    stats["skipped_items"].append(str(dest.relative_to(dest.parents[2])))
                    return False
                elif mode == "auto_rename":
                    # è‡ªåŠ¨é‡å‘½å
                    base = dest.stem
                    ext = dest.suffix
                    counter = 1
                    new_dest = dest.parent / f"{base}_{counter}{ext}"
                    while new_dest.exists():
                        counter += 1
                        new_dest = dest.parent / f"{base}_{counter}{ext}"
                    shutil.copy2(source, new_dest)
                    stats["renamed_items"].append(str(new_dest.relative_to(new_dest.parents[2])))
                    return True
            
        except Exception as e:
            stats["errors"].append(f"å¤åˆ¶æ–‡ä»¶å¤±è´¥ {source.name}: {str(e)}")
            return False
    
    def _import_node_info(self, temp_dir, root, mode, stats):
        """å¯¼å…¥èŠ‚ç‚¹ä¿¡æ¯"""
        try:
            node_info_dir = temp_dir / "node_info"
            if not node_info_dir.exists():
                return
            
            nodes_list_file = node_info_dir / "custom_nodes_list.json"
            if nodes_list_file.exists():
                with open(nodes_list_file, 'r', encoding='utf-8') as f:
                    nodes_data = json.load(f)
                
                # ä¿å­˜èŠ‚ç‚¹ä¿¡æ¯åˆ°userç›®å½•
                user_dir = root / "user" / "default"
                user_dir.mkdir(parents=True, exist_ok=True)
                
                dest = user_dir / "custom_nodes_info.json"
                if self._copy_file_with_mode(nodes_list_file, dest, mode, stats):
                    stats["imported_items"].append("èŠ‚ç‚¹ä¿¡æ¯")
                    stats["file_count"] += 1
            
        except Exception as e:
            stats["errors"].append(f"å¯¼å…¥èŠ‚ç‚¹ä¿¡æ¯å¤±è´¥: {str(e)}")
    
    def _import_frontend_settings(self, temp_dir, root, mode, stats):
        """å¯¼å…¥å‰ç«¯è®¾ç½®"""
        try:
            settings_dir = temp_dir / "frontend_settings"
            if not settings_dir.exists():
                return
            
            imported_count = 0
            for setting_file in settings_dir.glob("*.json"):
                # å¯¼å…¥åˆ°user/defaultç›®å½•
                dest_dir = root / "user" / "default"
                dest_dir.mkdir(parents=True, exist_ok=True)
                dest = dest_dir / setting_file.name
                
                if self._copy_file_with_mode(setting_file, dest, mode, stats):
                    imported_count += 1
            
            if imported_count > 0:
                stats["imported_items"].append(f"å‰ç«¯è®¾ç½® ({imported_count}ä¸ª)")
                stats["file_count"] += imported_count
            
        except Exception as e:
            stats["errors"].append(f"å¯¼å…¥å‰ç«¯è®¾ç½®å¤±è´¥: {str(e)}")
    
    def _import_dependencies(self, temp_dir, root, mode, stats):
        """å¯¼å…¥ç¯å¢ƒä¾èµ–"""
        try:
            deps_dir = temp_dir / "dependencies"
            if not deps_dir.exists():
                return
            
            # å¯¼å…¥requirements.txtï¼ˆä»…ä½œä¸ºå‚è€ƒï¼Œä¸è‡ªåŠ¨å®‰è£…ï¼‰
            req_file = deps_dir / "requirements.txt"
            if req_file.exists():
                dest = root / "imported_requirements.txt"
                if self._copy_file_with_mode(req_file, dest, mode, stats):
                    stats["imported_items"].append("ç¯å¢ƒä¾èµ–ä¿¡æ¯ï¼ˆéœ€æ‰‹åŠ¨å®‰è£…ï¼‰")
                    stats["file_count"] += 1
            
        except Exception as e:
            stats["errors"].append(f"å¯¼å…¥ç¯å¢ƒä¾èµ–å¤±è´¥: {str(e)}")
    
    def _import_workflows(self, temp_dir, root, mode, stats):
        """å¯¼å…¥å·¥ä½œæµæ–‡ä»¶"""
        try:
            workflow_dir = temp_dir / "workflows"
            if not workflow_dir.exists():
                return
            
            dest_dir = root / "user" / "default" / "workflows"
            dest_dir.mkdir(parents=True, exist_ok=True)
            
            imported_count = 0
            for workflow_file in workflow_dir.rglob("*.json"):
                rel_path = workflow_file.relative_to(workflow_dir)
                dest = dest_dir / rel_path
                if self._copy_file_with_mode(workflow_file, dest, mode, stats):
                    imported_count += 1
            
            if imported_count > 0:
                stats["imported_items"].append(f"å·¥ä½œæµæ–‡ä»¶ ({imported_count}ä¸ª)")
                stats["file_count"] += imported_count
            
        except Exception as e:
            stats["errors"].append(f"å¯¼å…¥å·¥ä½œæµå¤±è´¥: {str(e)}")
    
    def _import_inputs(self, temp_dir, root, mode, stats):
        """å¯¼å…¥è¾“å…¥æ–‡ä»¶"""
        try:
            input_dir = temp_dir / "input"
            if not input_dir.exists():
                return
            
            dest_dir = root / "input"
            dest_dir.mkdir(parents=True, exist_ok=True)
            
            imported_count = 0
            for input_file in input_dir.rglob("*"):
                if input_file.is_file():
                    rel_path = input_file.relative_to(input_dir)
                    dest = dest_dir / rel_path
                    if self._copy_file_with_mode(input_file, dest, mode, stats):
                        imported_count += 1
            
            if imported_count > 0:
                stats["imported_items"].append(f"è¾“å…¥æ–‡ä»¶ ({imported_count}ä¸ª)")
                stats["file_count"] += imported_count
            
        except Exception as e:
            stats["errors"].append(f"å¯¼å…¥è¾“å…¥æ–‡ä»¶å¤±è´¥: {str(e)}")
    
    def _import_outputs(self, temp_dir, root, mode, stats):
        """å¯¼å…¥è¾“å‡ºæ–‡ä»¶"""
        try:
            output_dir = temp_dir / "output"
            if not output_dir.exists():
                return
            
            dest_dir = root / "output"
            dest_dir.mkdir(parents=True, exist_ok=True)
            
            imported_count = 0
            for output_file in output_dir.rglob("*"):
                if output_file.is_file():
                    rel_path = output_file.relative_to(output_dir)
                    dest = dest_dir / rel_path
                    if self._copy_file_with_mode(output_file, dest, mode, stats):
                        imported_count += 1
            
            if imported_count > 0:
                stats["imported_items"].append(f"è¾“å‡ºæ–‡ä»¶ ({imported_count}ä¸ª)")
                stats["file_count"] += imported_count
            
        except Exception as e:
            stats["errors"].append(f"å¯¼å…¥è¾“å‡ºæ–‡ä»¶å¤±è´¥: {str(e)}")
    
    def _generate_import_success_report(self, source_path, stats, mode):
        """ç”Ÿæˆå¯¼å…¥æˆåŠŸæŠ¥å‘Š"""
        mode_names = {
            "overwrite": "è¦†ç›–æ¨¡å¼",
            "skip": "è·³è¿‡æ¨¡å¼",
            "auto_rename": "è‡ªåŠ¨é‡å‘½åæ¨¡å¼"
        }
        
        report = "âœ… é…ç½®å¯¼å…¥æˆåŠŸï¼\n\n"
        report += f"ğŸ“¦ å¯¼å…¥æ¥æºï¼š{source_path.name}\n"
        report += f"ğŸ“‚ å¯¼å…¥ç±»å‹ï¼š{stats.get('import_type', 'æœªçŸ¥')}\n"
        report += f"ğŸ”§ å¯¼å…¥æ¨¡å¼ï¼š{mode_names.get(mode, mode)}\n"
        report += f"ğŸ“Š å¯¼å…¥æ–‡ä»¶æ•°ï¼š{stats['file_count']} ä¸ª\n\n"
        
        if stats["backup_created"]:
            backup_path = stats.get('backup_path', 'å·²åˆ›å»º')
            report += f"ğŸ’¾ å¤‡ä»½ä½ç½®ï¼š{backup_path}\n\n"
        
        if stats["imported_items"]:
            report += "ğŸ“‹ å·²å¯¼å…¥å†…å®¹ï¼š\n"
            for item in stats["imported_items"]:
                report += f"  âœ“ {item}\n"
        
        if stats["renamed_items"]:
            report += f"\nğŸ”„ è‡ªåŠ¨é‡å‘½åï¼š{len(stats['renamed_items'])} ä¸ªæ–‡ä»¶\n"
        
        if stats["skipped_items"]:
            report += f"\nâ­ï¸ è·³è¿‡æ–‡ä»¶ï¼š{len(stats['skipped_items'])} ä¸ª\n"
        
        if stats["errors"]:
            report += "\nâš ï¸ éƒ¨åˆ†å†…å®¹å¯¼å…¥å¤±è´¥ï¼š\n"
            for error in stats["errors"]:
                report += f"  âœ— {error}\n"
        
        report += "\nğŸ’¡ æç¤ºï¼šå¦‚éœ€åº”ç”¨æ–°é…ç½®ï¼Œè¯·é‡å¯ComfyUI"
        
        return report


# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "ConfigExport": ConfigExport,
    "ConfigImport": ConfigImport
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ConfigExport": "é…ç½®æ–‡ä»¶ä¸¨å¯¼å‡º",
    "ConfigImport": "é…ç½®æ–‡ä»¶ä¸¨å¯¼å…¥"
}

