# -*- coding: utf-8 -*-
"""
QINGè°ƒè¯•å·¥å…·èŠ‚ç‚¹é›†åˆ
åŒ…å«LetMeSeeå’ŒShowMePureä¸¤ä¸ªæ ¸å¿ƒè°ƒè¯•èŠ‚ç‚¹
æ”¯æŒä»»æ„æ•°æ®ç±»å‹çš„è°ƒè¯•æ˜¾ç¤ºå’Œé€ä¼ 
"""

import json
import time
import sys
from datetime import datetime

# å¯é€‰ä¾èµ–ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨åŸºç¡€åŠŸèƒ½
try:
    import psutil
    HAS_PSUTIL = True
except ImportError:
    HAS_PSUTIL = False

try:
    import torch
    HAS_TORCH = True
except ImportError:
    HAS_TORCH = False


# å®šä¹‰é€šç”¨ç±»å‹ä»£ç†ï¼Œå…è®¸æ¥å—ä»»ä½•ç±»å‹çš„è¾“å…¥
class AlwaysEqualProxy(str):
    """ä»£ç†ç±»ï¼Œå…è®¸æ¥å—ä»»ä½•ç±»å‹çš„è¾“å…¥"""
    def __eq__(self, _):
        return True
    
    def __ne__(self, _):
        return False


# åˆ›å»ºä»»æ„ç±»å‹çš„å®ä¾‹
any_type = AlwaysEqualProxy("*")


class LetMeSee:
    """
    æˆ‘æƒ³çœ‹çœ‹ - é€šç”¨è°ƒè¯•å·¥å…·
    æ˜¾ç¤ºä»»ä½•ç±»å‹æ•°æ®çš„è¯¦ç»†åˆ†æï¼ŒåŒ…å«æ•°æ®ç±»å‹ã€è¿è¡Œæ—¶é•¿ã€ç³»ç»Ÿèµ„æºä½¿ç”¨ç­‰ä¿¡æ¯
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {}, 
            "optional": {"source": (any_type, {})},
            "hidden": {"unique_id": "UNIQUE_ID", "extra_pnginfo": "EXTRA_PNGINFO"}
        }
    
    RETURN_TYPES = (any_type,)
    RETURN_NAMES = ('source',)
    INPUT_IS_LIST = True
    OUTPUT_NODE = True
    FUNCTION = "show_data"
    CATEGORY = "ğŸ¨QING/è°ƒè¯•å·¥å…·"
    
    def show_data(self, unique_id=None, extra_pnginfo=None, **kwargs):
        """
        å¤„ç†è¾“å…¥æ•°æ®å¹¶åœ¨UIä¸­æ˜¾ç¤ºï¼ŒåŒ…å«ç³»ç»Ÿä¿¡æ¯ç»Ÿè®¡
        """
        start_time = time.time()
        
        # è·å–ç³»ç»Ÿä¿¡æ¯
        system_info = self._get_system_info()
        
        # æ”¶é›†UIæ˜¾ç¤ºå†…å®¹å’ŒåŸå§‹è¾“å‡ºæ•°æ®
        ui_values = []
        output_data = []
        
        if "source" in kwargs:
            for val in kwargs['source']:
                try:
                    # ç”Ÿæˆåˆ†ææŠ¥å‘Šç”¨äºUIæ˜¾ç¤º
                    analysis_result = self._analyze_data(val, start_time, system_info)
                    ui_values.append(analysis_result)
                    # ä¿å­˜åŸå§‹æ•°æ®ç”¨äºè¾“å‡ºç«¯å£
                    output_data.append(val)
                except Exception:
                    ui_values.append(str(val))
                    output_data.append(val)

        # æ›´æ–°å·¥ä½œæµä¿¡æ¯ï¼ˆUIæ˜¾ç¤ºç”¨ï¼‰
        if not extra_pnginfo:
            pass
        elif (not isinstance(extra_pnginfo[0], dict) or "workflow" not in extra_pnginfo[0]):
            pass
        else:
            workflow = extra_pnginfo[0]["workflow"]
            node = next((x for x in workflow["nodes"] if str(x["id"]) == unique_id[0]), None)
            if node:
                node["widgets_values"] = [ui_values]
        
        # è¿”å›ç»“æœï¼šUIæ˜¾ç¤ºåˆ†ææŠ¥å‘Šï¼Œè¾“å‡ºç«¯å£ä¼ é€’åŸå§‹æ•°æ®
        if isinstance(output_data, list) and len(output_data) == 1:
            result = {"ui": {"text": ui_values}, "result": (output_data[0],), }
        else:
            result = {"ui": {"text": ui_values}, "result": (output_data,), }
            
        return result

    def _get_system_info(self):
        """è·å–ç³»ç»Ÿä¿¡æ¯"""
        info = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        }
        
        # å†…å­˜ä¿¡æ¯
        if HAS_PSUTIL:
            try:
                memory = psutil.virtual_memory()
                info["memory_mb"] = memory.used / 1024 / 1024
                info["memory_percent"] = memory.percent
            except:
                info["memory_mb"] = 0
                info["memory_percent"] = 0
        else:
            info["memory_mb"] = 0
            info["memory_percent"] = 0
        
        # GPUä¿¡æ¯
        if HAS_TORCH:
            try:
                import torch
                if torch.cuda.is_available():
                    info["gpu_memory_mb"] = torch.cuda.memory_allocated() / 1024 / 1024
                    info["gpu_memory_cached_mb"] = torch.cuda.memory_reserved() / 1024 / 1024
                    info["gpu_count"] = torch.cuda.device_count()
                    info["gpu_name"] = torch.cuda.get_device_name(0) if torch.cuda.device_count() > 0 else "Unknown"
                else:
                    info["gpu_memory_mb"] = 0
                    info["gpu_memory_cached_mb"] = 0
                    info["gpu_count"] = 0
                    info["gpu_name"] = "No GPU"
            except:
                info["gpu_memory_mb"] = 0
                info["gpu_memory_cached_mb"] = 0
                info["gpu_count"] = 0
                info["gpu_name"] = "No GPU"
        else:
            info["gpu_memory_mb"] = 0
            info["gpu_memory_cached_mb"] = 0
            info["gpu_count"] = 0
            info["gpu_name"] = "No GPU"
            
        return info

    def _analyze_data(self, data, start_time, system_info):
        """åˆ†ææ•°æ®å¹¶ç”Ÿæˆç²¾ç®€æŠ¥å‘Š"""
        current_time = time.time()
        execution_time = current_time - start_time
        
        # åŸºç¡€æ•°æ®ä¿¡æ¯
        data_type = type(data).__name__
        data_size = sys.getsizeof(data)
        
        # æ„å»ºç²¾ç®€æŠ¥å‘Š
        report_lines = [
            "ğŸ“Š æ•°æ®åˆ†æ",
            f"ğŸ•’ {system_info['timestamp']} | âš¡ {execution_time:.3f}s",
            "",
            f"ç±»å‹: {data_type} | å¤§å°: {data_size/1024:.1f}KB",
        ]
        
        # Tensorä¿¡æ¯ï¼ˆç²¾ç®€ç‰ˆï¼‰
        if HAS_TORCH and 'torch' in str(type(data)):
            try:
                import torch
                if isinstance(data, torch.Tensor):
                    shape_str = "x".join(map(str, data.shape))
                    report_lines.append(f"å½¢çŠ¶: {shape_str} | è®¾å¤‡: {data.device} | ç±»å‹: {data.dtype}")
                    
                    # ç®€åŒ–æ•°å€¼ç»Ÿè®¡
                    if data.numel() > 0 and data.dtype in [torch.float32, torch.float64, torch.float16]:
                        try:
                            min_val = data.min().item()
                            max_val = data.max().item()
                            mean_val = data.mean().item()
                            report_lines.append(f"èŒƒå›´: {min_val:.3f}~{max_val:.3f} | å‡å€¼: {mean_val:.3f}")
                        except:
                            pass
            except:
                pass
        
        # å®¹å™¨ç±»å‹ä¿¡æ¯
        elif hasattr(data, '__len__'):
            try:
                report_lines.append(f"é•¿åº¦: {len(data)}")
            except:
                pass
        
        # ç²¾ç®€ç³»ç»Ÿèµ„æºä¿¡æ¯
        report_lines.extend([
            "",
            f"ğŸ’» å†…å­˜: {system_info['memory_mb']:.0f}MB ({system_info['memory_percent']:.0f}%)",
            f"ğŸ–¥ï¸ GPU: {system_info['gpu_memory_mb']:.0f}MB | {system_info['gpu_name']}",
            "",
            "ğŸ“„ å†…å®¹:",
        ])
        
        # å®Œæ•´æ•°æ®å†…å®¹æ˜¾ç¤ºï¼ˆæ— æˆªæ–­ï¼‰
        try:
            if isinstance(data, str):
                content = data
            elif isinstance(data, (int, float, bool)):
                content = str(data)
            elif isinstance(data, list):
                content = str(data)
            else:
                content = json.dumps(data, ensure_ascii=False, indent=1, default=str)
        except:
            content = str(data)
            
        report_lines.append(content)
        
        return "\n".join(report_lines)


class ShowMePure:
    """
    è®©æˆ‘çœ‹çœ‹ - æç®€å†…å®¹æ˜¾ç¤ºå·¥å…·
    ç›´æ¥è¾“å‡ºåŸå§‹æ•°æ®å†…å®¹ï¼Œæ— ä»»ä½•æ ¼å¼åŒ–æˆ–é¢å¤–ä¿¡æ¯
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {}, 
            "optional": {"source": (any_type, {})},
            "hidden": {"unique_id": "UNIQUE_ID", "extra_pnginfo": "EXTRA_PNGINFO"}
        }
    
    RETURN_TYPES = (any_type,)
    RETURN_NAMES = ('source',)
    INPUT_IS_LIST = True
    OUTPUT_NODE = True
    FUNCTION = "show_pure_data"
    CATEGORY = "ğŸ¨QING/è°ƒè¯•å·¥å…·"
    
    def show_pure_data(self, unique_id=None, extra_pnginfo=None, **kwargs):
        """
        å¤„ç†è¾“å…¥æ•°æ®å¹¶åœ¨UIä¸­æ˜¾ç¤ºçº¯å‡€å†…å®¹ï¼Œæ— ç³»ç»Ÿåˆ†æ
        """
        # æ”¶é›†UIæ˜¾ç¤ºå†…å®¹å’ŒåŸå§‹è¾“å‡ºæ•°æ®
        ui_values = []
        output_data = []
        
        if "source" in kwargs:
            for val in kwargs['source']:
                try:
                    # ç”Ÿæˆçº¯å‡€å†…å®¹æ˜¾ç¤º
                    pure_content = self._show_pure_content(val)
                    ui_values.append(pure_content)
                    # ä¿å­˜åŸå§‹æ•°æ®ç”¨äºè¾“å‡ºç«¯å£
                    output_data.append(val)
                except Exception:
                    ui_values.append(str(val))
                    output_data.append(val)

        # æ›´æ–°å·¥ä½œæµä¿¡æ¯ï¼ˆUIæ˜¾ç¤ºç”¨ï¼‰
        if not extra_pnginfo:
            pass
        elif (not isinstance(extra_pnginfo[0], dict) or "workflow" not in extra_pnginfo[0]):
            pass
        else:
            workflow = extra_pnginfo[0]["workflow"]
            node = next((x for x in workflow["nodes"] if str(x["id"]) == unique_id[0]), None)
            if node:
                node["widgets_values"] = [ui_values]
        
        # è¿”å›ç»“æœï¼šUIæ˜¾ç¤ºçº¯å‡€å†…å®¹ï¼Œè¾“å‡ºç«¯å£ä¼ é€’åŸå§‹æ•°æ®
        if isinstance(output_data, list) and len(output_data) == 1:
            result = {"ui": {"text": ui_values}, "result": (output_data[0],), }
        else:
            result = {"ui": {"text": ui_values}, "result": (output_data,), }
            
        return result

    def _show_pure_content(self, data):
        """æ˜¾ç¤ºçº¯å‡€æ•°æ®å†…å®¹ï¼Œå®Œå…¨æ— æ ¼å¼åŒ–"""
        # ç›´æ¥è¿”å›æ•°æ®å†…å®¹ï¼Œæ— ä»»ä½•é¢å¤–ä¿¡æ¯
        try:
            if isinstance(data, str):
                return data
            elif isinstance(data, (int, float, bool)):
                return str(data)
            elif isinstance(data, list):
                return str(data)
            else:
                return json.dumps(data, ensure_ascii=False, indent=1, default=str)
        except:
            return str(data)


# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "LetMeSee": LetMeSee,
    "ShowMePure": ShowMePure
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "LetMeSee": "æˆ‘æƒ³çœ‹çœ‹",
    "ShowMePure": "è®©æˆ‘çœ‹çœ‹"
}
