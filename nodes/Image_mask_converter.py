# -*- coding: utf-8 -*-
import torch

class ImageMaskConverter:
    """å›¾åƒä¸é®ç½©è½¬æ¢èŠ‚ç‚¹"""
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "channel": (["red", "green", "blue", "alpha"], {"default": "red"}),
            },
            "optional": {
                "image1": ("IMAGE",),
                "image2": ("IMAGE",),
                "mask1": ("MASK",),
                "mask2": ("MASK",),
            }
        }

    CATEGORY = "ğŸ¨QING/å›¾åƒå¤„ç†"
    RETURN_TYPES = ("MASK", "MASK", "IMAGE", "IMAGE")
    RETURN_NAMES = ("é®ç½©1", "é®ç½©2", "å›¾åƒ1", "å›¾åƒ2")
    FUNCTION = "convert"

    def convert(self, channel, image1=None, image2=None, mask1=None, mask2=None):
        """ä¸»è½¬æ¢å‡½æ•°"""
        # å›¾åƒè½¬é®ç½©
        output_mask1 = self._image_to_mask(image1, channel) if image1 is not None else self._empty_mask()
        output_mask2 = self._image_to_mask(image2, channel) if image2 is not None else self._empty_mask()
        
        # é®ç½©è½¬å›¾åƒ
        output_image1 = self._mask_to_image(mask1) if mask1 is not None else self._empty_image()
        output_image2 = self._mask_to_image(mask2) if mask2 is not None else self._empty_image()
        
        return (output_mask1, output_mask2, output_image1, output_image2)
    
    def _image_to_mask(self, image, channel):
        """å›¾åƒè½¬é®ç½©"""
        if len(image.shape) == 4:
            image = image[0]  # å–ç¬¬ä¸€å¼ 
        
        height, width, channels = image.shape
        
        if channel == "red" and channels >= 1:
            return image[:, :, 0]
        elif channel == "green" and channels >= 2:
            return image[:, :, 1]  
        elif channel == "blue" and channels >= 3:
            return image[:, :, 2]
        elif channel == "alpha":
            if channels >= 4:
                return image[:, :, 3]
            else:
                # æ²¡æœ‰alphaé€šé“æ—¶ï¼ŒåŸºäºäº®åº¦åˆ›å»ºé®ç½©
                if channels >= 3:
                    # RGBè½¬ç°åº¦ï¼š0.299*R + 0.587*G + 0.114*B
                    gray = 0.299 * image[:, :, 0] + 0.587 * image[:, :, 1] + 0.114 * image[:, :, 2]
                    return gray
                else:
                    # å•é€šé“å›¾åƒç›´æ¥ä½¿ç”¨
                    return image[:, :, 0]
        else:
            # é»˜è®¤è¿”å›å…¨ç™½é®ç½©
            return torch.ones((height, width), dtype=torch.float32, device=image.device)
    
    def _mask_to_image(self, mask):
        """é®ç½©è½¬ç°åº¦å›¾åƒ"""
        if len(mask.shape) == 3:
            mask = mask[0]  # å–ç¬¬ä¸€å¼ 
        
        # åˆ›å»ºRGBå›¾åƒï¼Œæ‰€æœ‰é€šé“éƒ½æ˜¯é®ç½©å€¼
        height, width = mask.shape
        image = torch.stack([mask, mask, mask], dim=2)
        
        return image.unsqueeze(0)  # æ·»åŠ batchç»´åº¦
    
    def _empty_mask(self):
        """ç©ºé®ç½©"""
        return torch.zeros((1, 64, 64), dtype=torch.float32)
    
    def _empty_image(self):
        """ç©ºå›¾åƒ"""
        return torch.zeros((1, 64, 64, 3), dtype=torch.float32)

# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "ImageMaskConverter": ImageMaskConverter
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ImageMaskConverter": "å›¾åƒé®ç½©è½¬æ¢"
}